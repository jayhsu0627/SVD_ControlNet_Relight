NODELIST=gammagpu10
MASTER_ADDR=gammagpu10
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
srun: error: gammagpu10: tasks 0,2-3: Exited with exit code 1
WARNING:accelerate.utils.other:Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
INFO:__main__:Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

INFO:__main__:Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: fp16

INFO:__main__:Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: fp16

INFO:__main__:Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: fp16

prediction_type: v_prediction
prediction_type: v_prediction
{'final_sigmas_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
prediction_type: v_prediction
prediction_type: v_prediction
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionControlNetModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionControlNetModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
INFO:__main__:Initializing controlnet weights from unet
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionControlNetModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionControlNetModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
modify_layers in progress: torch.Size([6, 1, 16])
modify_layers in progress: 16 320
modify_layers in progress: torch.Size([6, 1, 16])
modify_layers in progress: 16 320
modify_layers in progress: torch.Size([6, 1, 16])
modify_layers in progress: 16 320
modify_layers in progress: torch.Size([6, 1, 16])
modify_layers in progress: 16 320
data scale: 5910
length 5910
sample size (512, 512)
data scale: 5910
length 5910
sample size (512, 512)
data scale: 5910
length 5910
sample size (512, 512)
data scale: 5910
length 5910
sample size (512, 512)
gammagpu10:1258844:1258844 [0] NCCL INFO Bootstrap : Using bond0:192.168.44.21<0>
gammagpu10:1258844:1258844 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu10:1258844:1258844 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.20.5+cuda12.4
gammagpu10:1258845:1258845 [1] NCCL INFO cudaDriverVersion 12040
gammagpu10:1258845:1258845 [1] NCCL INFO Bootstrap : Using bond0:192.168.44.21<0>
gammagpu10:1258845:1258845 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu10:1258847:1258847 [3] NCCL INFO cudaDriverVersion 12040
gammagpu10:1258847:1258847 [3] NCCL INFO Bootstrap : Using bond0:192.168.44.21<0>
gammagpu10:1258847:1258847 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu10:1258844:1258966 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu10:1258845:1258967 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu10:1258844:1258966 [0] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.21<0> [1]virbr0:192.168.122.1<0>
gammagpu10:1258844:1258966 [0] NCCL INFO Using non-device net plugin version 0
gammagpu10:1258844:1258966 [0] NCCL INFO Using network Socket
gammagpu10:1258845:1258967 [1] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.21<0> [1]virbr0:192.168.122.1<0>
gammagpu10:1258845:1258967 [1] NCCL INFO Using non-device net plugin version 0
gammagpu10:1258845:1258967 [1] NCCL INFO Using network Socket
gammagpu10:1258847:1258968 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu10:1258847:1258968 [3] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.21<0> [1]virbr0:192.168.122.1<0>
gammagpu10:1258847:1258968 [3] NCCL INFO Using non-device net plugin version 0
gammagpu10:1258847:1258968 [3] NCCL INFO Using network Socket
gammagpu10:1258846:1258846 [2] NCCL INFO cudaDriverVersion 12040
gammagpu10:1258846:1258846 [2] NCCL INFO Bootstrap : Using bond0:192.168.44.21<0>
gammagpu10:1258846:1258846 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu10:1258846:1258969 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu10:1258846:1258969 [2] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.21<0> [1]virbr0:192.168.122.1<0>
gammagpu10:1258846:1258969 [2] NCCL INFO Using non-device net plugin version 0
gammagpu10:1258846:1258969 [2] NCCL INFO Using network Socket
gammagpu10:1258844:1258966 [0] NCCL INFO comm 0x556abc241300 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x4cc6dc70c71cd63f - Init START
gammagpu10:1258847:1258968 [3] NCCL INFO comm 0x556948807600 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c1000 commId 0x4cc6dc70c71cd63f - Init START
gammagpu10:1258846:1258969 [2] NCCL INFO comm 0x5642a73ca700 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 81000 commId 0x4cc6dc70c71cd63f - Init START
gammagpu10:1258845:1258967 [1] NCCL INFO comm 0x559f4b20c700 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 41000 commId 0x4cc6dc70c71cd63f - Init START
gammagpu10:1258846:1258969 [2] NCCL INFO NVLS multicast support is not available on dev 2
gammagpu10:1258847:1258968 [3] NCCL INFO NVLS multicast support is not available on dev 3
gammagpu10:1258844:1258966 [0] NCCL INFO NVLS multicast support is not available on dev 0
gammagpu10:1258845:1258967 [1] NCCL INFO NVLS multicast support is not available on dev 1
gammagpu10:1258844:1258966 [0] NCCL INFO comm 0x556abc241300 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gammagpu10:1258846:1258969 [2] NCCL INFO comm 0x5642a73ca700 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gammagpu10:1258845:1258967 [1] NCCL INFO comm 0x559f4b20c700 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 00/04 :    0   1   2   3
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 01/04 :    0   1   2   3
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 02/04 :    0   1   2   3
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 03/04 :    0   1   2   3
gammagpu10:1258847:1258968 [3] NCCL INFO comm 0x556948807600 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gammagpu10:1258846:1258969 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
gammagpu10:1258845:1258967 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
gammagpu10:1258844:1258966 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1
gammagpu10:1258846:1258969 [2] NCCL INFO P2P Chunksize set to 131072
gammagpu10:1258845:1258967 [1] NCCL INFO P2P Chunksize set to 131072
gammagpu10:1258844:1258966 [0] NCCL INFO P2P Chunksize set to 131072
gammagpu10:1258847:1258968 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
gammagpu10:1258847:1258968 [3] NCCL INFO P2P Chunksize set to 131072
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 01/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu10:1258844:1258966 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Connected all rings
gammagpu10:1258844:1258966 [0] NCCL INFO Connected all rings
gammagpu10:1258846:1258969 [2] NCCL INFO Connected all rings
gammagpu10:1258847:1258968 [3] NCCL INFO Connected all rings
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu10:1258846:1258969 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu10:1258845:1258967 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu10:1258847:1258968 [3] NCCL INFO Connected all trees
gammagpu10:1258847:1258968 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu10:1258847:1258968 [3] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu10:1258844:1258966 [0] NCCL INFO Connected all trees
gammagpu10:1258844:1258966 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu10:1258844:1258966 [0] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu10:1258846:1258969 [2] NCCL INFO Connected all trees
gammagpu10:1258846:1258969 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu10:1258846:1258969 [2] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu10:1258845:1258967 [1] NCCL INFO Connected all trees
gammagpu10:1258845:1258967 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu10:1258845:1258967 [1] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu10:1258844:1258966 [0] NCCL INFO comm 0x556abc241300 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x4cc6dc70c71cd63f - Init COMPLETE
gammagpu10:1258846:1258969 [2] NCCL INFO comm 0x5642a73ca700 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 81000 commId 0x4cc6dc70c71cd63f - Init COMPLETE
gammagpu10:1258847:1258968 [3] NCCL INFO comm 0x556948807600 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c1000 commId 0x4cc6dc70c71cd63f - Init COMPLETE
gammagpu10:1258845:1258967 [1] NCCL INFO comm 0x559f4b20c700 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 41000 commId 0x4cc6dc70c71cd63f - Init COMPLETE
wandb: Tracking run with wandb version 0.17.8
wandb: Run data is saved locally in /fs/nexus-scratch/sjxu/svd-temporal-controlnet/wandb/run-20250113_110017-tkupym8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-star-220
wandb: ⭐️ View project at https://wandb.ai/sjxu_gamma/SVD_Con_Mul
wandb: 🚀 View run at https://wandb.ai/sjxu_gamma/SVD_Con_Mul/runs/tkupym8a
INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 4728
INFO:__main__:  Num Epochs = 120
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 64
INFO:__main__:  Gradient Accumulation steps = 16
INFO:__main__:  Total optimization steps = 8880
  0%|          | 0/8880 [00:00<?, ?it/s]Steps:   0%|          | 0/8880 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
    main()
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
    conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
    latents = vae.encode(t).latent_dist.sample()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
    h = self.encoder(x)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
    sample = self.conv_in(sample)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (float) and bias type (c10::Half) should be the same
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
[rank0]:     main()
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
[rank0]:     conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
[rank0]:     latents = vae.encode(t).latent_dist.sample()
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
[rank0]:     return method(self, *args, **kwargs)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
[rank0]:     h = self.encoder(x)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
[rank0]:     sample = self.conv_in(sample)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
[rank0]:     return self._conv_forward(input, self.weight, self.bias)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
[rank0]:     return F.conv2d(input, weight, bias, self.stride,
[rank0]: RuntimeError: Input type (float) and bias type (c10::Half) should be the same
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
    main()
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
    conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
    latents = vae.encode(t).latent_dist.sample()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
    h = self.encoder(x)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
    sample = self.conv_in(sample)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (float) and bias type (c10::Half) should be the same
[rank3]: Traceback (most recent call last):
[rank3]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
[rank3]:     main()
[rank3]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
[rank3]:     conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
[rank3]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
[rank3]:     latents = vae.encode(t).latent_dist.sample()
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
[rank3]:     return method(self, *args, **kwargs)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
[rank3]:     h = self.encoder(x)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
[rank3]:     sample = self.conv_in(sample)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank3]:     return self._call_impl(*args, **kwargs)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank3]:     return forward_call(*args, **kwargs)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
[rank3]:     return self._conv_forward(input, self.weight, self.bias)
[rank3]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
[rank3]:     return F.conv2d(input, weight, bias, self.stride,
[rank3]: RuntimeError: Input type (float) and bias type (c10::Half) should be the same
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
    main()
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
    conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
    latents = vae.encode(t).latent_dist.sample()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
    h = self.encoder(x)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
    sample = self.conv_in(sample)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (float) and bias type (c10::Half) should be the same
[rank2]: Traceback (most recent call last):
[rank2]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
[rank2]:     main()
[rank2]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
[rank2]:     conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
[rank2]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
[rank2]:     latents = vae.encode(t).latent_dist.sample()
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
[rank2]:     return method(self, *args, **kwargs)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
[rank2]:     h = self.encoder(x)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
[rank2]:     sample = self.conv_in(sample)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank2]:     return self._call_impl(*args, **kwargs)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank2]:     return forward_call(*args, **kwargs)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
[rank2]:     return self._conv_forward(input, self.weight, self.bias)
[rank2]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
[rank2]:     return F.conv2d(input, weight, bias, self.stride,
[rank2]: RuntimeError: Input type (float) and bias type (c10::Half) should be the same
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
    main()
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
    conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
    latents = vae.encode(t).latent_dist.sample()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
    return method(self, *args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
    h = self.encoder(x)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
    sample = self.conv_in(sample)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (float) and bias type (c10::Half) should be the same
[rank1]: Traceback (most recent call last):
[rank1]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 2023, in <module>
[rank1]:     main()
[rank1]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1606, in main
[rank1]:     conditional_latents = tensor_to_vae_latent(conditional_pixel_values, vae)
[rank1]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 448, in tensor_to_vae_latent
[rank1]:     latents = vae.encode(t).latent_dist.sample()
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/accelerate_utils.py", line 46, in wrapper
[rank1]:     return method(self, *args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/autoencoder_kl_temporal_decoder.py", line 334, in encode
[rank1]:     h = self.encoder(x)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/models/autoencoders/vae.py", line 143, in forward
[rank1]:     sample = self.conv_in(sample)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank1]:     return self._call_impl(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank1]:     return forward_call(*args, **kwargs)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 458, in forward
[rank1]:     return self._conv_forward(input, self.weight, self.bias)
[rank1]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 454, in _conv_forward
[rank1]:     return F.conv2d(input, weight, bias, self.stride,
[rank1]: RuntimeError: Input type (float) and bias type (c10::Half) should be the same
W0113 11:00:29.208456 139795340149504 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1258844 closing signal SIGTERM
W0113 11:00:29.208809 139795340149504 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1258845 closing signal SIGTERM
W0113 11:00:29.208876 139795340149504 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1258846 closing signal SIGTERM
E0113 11:00:29.573138 139795340149504 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 3 (pid: 1258847) of binary: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/python
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_svd_controlnet.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-01-13_11:00:29
  host      : gammagpu10.umiacs.umd.edu
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 1258847)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: gammagpu10: task 1: Exited with exit code 1
