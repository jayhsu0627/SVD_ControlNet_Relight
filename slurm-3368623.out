NODELIST=gammagpu12
MASTER_ADDR=gammagpu12
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
The following values were not passed to `accelerate launch` and had defaults used instead:
	`--num_processes` was set to a value of `4`
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--num_machines` was set to a value of `1`
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = agent.run()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = self._invoke_run(role)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    self._initialize_workers(self._worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    self._rendezvous(worker_group)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
srun: error: gammagpu12: tasks 0-1,3: Exited with exit code 1
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_fwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.
  @torch.library.impl_abstract("xformers_flash::flash_bwd")
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/kornia/feature/lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
11/28/2024 23:06:57 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
{'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
wandb: Currently logged in as: sjxu (sjxu_gamma). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /fs/nexus-scratch/sjxu/.netrc
11/28/2024 23:06:57 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: fp16

/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
11/28/2024 23:06:57 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: fp16

/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
11/28/2024 23:06:57 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: fp16

/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.
  torch.utils._pytree._register_pytree_node(
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
Loading model from: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/weights/v0.1/alex.pth
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
11/28/2024 23:07:00 - INFO - __main__ - Initializing controlnet weights from unet
layers per block is 2
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
FrozenDict([('sample_size', 96), ('in_channels', 8), ('out_channels', 4), ('down_block_types', ['CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'CrossAttnDownBlockSpatioTemporal', 'DownBlockSpatioTemporal']), ('up_block_types', ['UpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal', 'CrossAttnUpBlockSpatioTemporal']), ('block_out_channels', [320, 640, 1280, 1280]), ('addition_time_embed_dim', 256), ('projection_class_embeddings_input_dim', 768), ('layers_per_block', 2), ('cross_attention_dim', 1024), ('transformer_layers_per_block', 1), ('num_attention_heads', [5, 10, 20, 20]), ('num_frames', 14), ('_class_name', 'UNetSpatioTemporalConditionModel'), ('_diffusers_version', '0.24.0.dev0'), ('_name_or_path', 'stabilityai/stable-video-diffusion-img2vid')])
layers per block is 2
1
1
1
1
data scale: 5910
length 5910
sample size (512, 512)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
data scale: 5910
length 5910
sample size (512, 512)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
data scale: 5910
length 5910
sample size (512, 512)
data scale: 5910
length 5910
sample size (512, 512)
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
gammagpu12:662667:662667 [0] NCCL INFO Bootstrap : Using bond0:192.168.44.23<0>
gammagpu12:662667:662667 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu12:662667:662667 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.20.5+cuda12.4
gammagpu12:662670:662670 [3] NCCL INFO cudaDriverVersion 12040
gammagpu12:662670:662670 [3] NCCL INFO Bootstrap : Using bond0:192.168.44.23<0>
gammagpu12:662670:662670 [3] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu12:662668:662668 [1] NCCL INFO cudaDriverVersion 12040
gammagpu12:662669:662669 [2] NCCL INFO cudaDriverVersion 12040
gammagpu12:662669:662669 [2] NCCL INFO Bootstrap : Using bond0:192.168.44.23<0>
gammagpu12:662668:662668 [1] NCCL INFO Bootstrap : Using bond0:192.168.44.23<0>
gammagpu12:662668:662668 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu12:662669:662669 [2] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
gammagpu12:662670:662793 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu12:662670:662793 [3] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.23<0> [1]virbr0:192.168.122.1<0>
gammagpu12:662670:662793 [3] NCCL INFO Using non-device net plugin version 0
gammagpu12:662670:662793 [3] NCCL INFO Using network Socket
gammagpu12:662669:662794 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu12:662669:662794 [2] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.23<0> [1]virbr0:192.168.122.1<0>
gammagpu12:662669:662794 [2] NCCL INFO Using non-device net plugin version 0
gammagpu12:662669:662794 [2] NCCL INFO Using network Socket
gammagpu12:662667:662792 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu12:662667:662792 [0] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.23<0> [1]virbr0:192.168.122.1<0>
gammagpu12:662667:662792 [0] NCCL INFO Using non-device net plugin version 0
gammagpu12:662667:662792 [0] NCCL INFO Using network Socket
gammagpu12:662668:662795 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.
gammagpu12:662668:662795 [1] NCCL INFO NET/Socket : Using [0]bond0:192.168.44.23<0> [1]virbr0:192.168.122.1<0>
gammagpu12:662668:662795 [1] NCCL INFO Using non-device net plugin version 0
gammagpu12:662668:662795 [1] NCCL INFO Using network Socket
gammagpu12:662667:662792 [0] NCCL INFO comm 0x55efb1a0d580 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x3998a36ebe356d68 - Init START
gammagpu12:662668:662795 [1] NCCL INFO comm 0x564f641707c0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 41000 commId 0x3998a36ebe356d68 - Init START
gammagpu12:662669:662794 [2] NCCL INFO comm 0x55ddfb504180 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 81000 commId 0x3998a36ebe356d68 - Init START
gammagpu12:662670:662793 [3] NCCL INFO comm 0x55984747a7c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c1000 commId 0x3998a36ebe356d68 - Init START
gammagpu12:662670:662793 [3] NCCL INFO NVLS multicast support is not available on dev 3
gammagpu12:662667:662792 [0] NCCL INFO NVLS multicast support is not available on dev 0
gammagpu12:662668:662795 [1] NCCL INFO NVLS multicast support is not available on dev 1
gammagpu12:662669:662794 [2] NCCL INFO NVLS multicast support is not available on dev 2
gammagpu12:662668:662795 [1] NCCL INFO comm 0x564f641707c0 rank 1 nRanks 4 nNodes 1 localRanks 4 localRank 1 MNNVL 0
gammagpu12:662667:662792 [0] NCCL INFO comm 0x55efb1a0d580 rank 0 nRanks 4 nNodes 1 localRanks 4 localRank 0 MNNVL 0
gammagpu12:662669:662794 [2] NCCL INFO comm 0x55ddfb504180 rank 2 nRanks 4 nNodes 1 localRanks 4 localRank 2 MNNVL 0
gammagpu12:662670:662793 [3] NCCL INFO comm 0x55984747a7c0 rank 3 nRanks 4 nNodes 1 localRanks 4 localRank 3 MNNVL 0
gammagpu12:662668:662795 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0 [2] 2/-1/-1->1->0 [3] 2/-1/-1->1->0
gammagpu12:662668:662795 [1] NCCL INFO P2P Chunksize set to 131072
gammagpu12:662667:662792 [0] NCCL INFO Channel 00/04 :    0   1   2   3
gammagpu12:662669:662794 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1
gammagpu12:662667:662792 [0] NCCL INFO Channel 01/04 :    0   1   2   3
gammagpu12:662669:662794 [2] NCCL INFO P2P Chunksize set to 131072
gammagpu12:662670:662793 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2
gammagpu12:662667:662792 [0] NCCL INFO Channel 02/04 :    0   1   2   3
gammagpu12:662667:662792 [0] NCCL INFO Channel 03/04 :    0   1   2   3
gammagpu12:662670:662793 [3] NCCL INFO P2P Chunksize set to 131072
gammagpu12:662667:662792 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1
gammagpu12:662667:662792 [0] NCCL INFO P2P Chunksize set to 131072
gammagpu12:662669:662794 [2] NCCL INFO Channel 00/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 01/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 00/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 02/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 00/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu12:662667:662792 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 01/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu12:662667:662792 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 03/0 : 2[2] -> 3[3] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 01/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu12:662667:662792 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 02/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 02/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu12:662667:662792 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 03/0 : 3[3] -> 0[0] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 03/0 : 1[1] -> 2[2] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Connected all rings
gammagpu12:662667:662792 [0] NCCL INFO Connected all rings
gammagpu12:662669:662794 [2] NCCL INFO Connected all rings
gammagpu12:662670:662793 [3] NCCL INFO Connected all rings
gammagpu12:662670:662793 [3] NCCL INFO Channel 00/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 01/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 02/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu12:662670:662793 [3] NCCL INFO Channel 03/0 : 3[3] -> 2[2] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 00/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 01/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 02/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu12:662669:662794 [2] NCCL INFO Channel 03/0 : 2[2] -> 1[1] via P2P/CUMEM
gammagpu12:662668:662795 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/CUMEM
gammagpu12:662667:662792 [0] NCCL INFO Connected all trees
gammagpu12:662667:662792 [0] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu12:662667:662792 [0] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu12:662668:662795 [1] NCCL INFO Connected all trees
gammagpu12:662668:662795 [1] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu12:662668:662795 [1] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu12:662670:662793 [3] NCCL INFO Connected all trees
gammagpu12:662670:662793 [3] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu12:662670:662793 [3] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu12:662669:662794 [2] NCCL INFO Connected all trees
gammagpu12:662669:662794 [2] NCCL INFO threadThresholds 8/8/64 | 32/8/64 | 512 | 512
gammagpu12:662669:662794 [2] NCCL INFO 4 coll channels, 0 collnet channels, 0 nvls channels, 4 p2p channels, 2 p2p channels per peer
gammagpu12:662668:662795 [1] NCCL INFO comm 0x564f641707c0 rank 1 nranks 4 cudaDev 1 nvmlDev 1 busId 41000 commId 0x3998a36ebe356d68 - Init COMPLETE
gammagpu12:662670:662793 [3] NCCL INFO comm 0x55984747a7c0 rank 3 nranks 4 cudaDev 3 nvmlDev 3 busId c1000 commId 0x3998a36ebe356d68 - Init COMPLETE
gammagpu12:662669:662794 [2] NCCL INFO comm 0x55ddfb504180 rank 2 nranks 4 cudaDev 2 nvmlDev 2 busId 81000 commId 0x3998a36ebe356d68 - Init COMPLETE
gammagpu12:662667:662792 [0] NCCL INFO comm 0x55efb1a0d580 rank 0 nranks 4 cudaDev 0 nvmlDev 0 busId 1000 commId 0x3998a36ebe356d68 - Init COMPLETE
wandb: Tracking run with wandb version 0.17.8
wandb: Run data is saved locally in /fs/nexus-scratch/sjxu/svd-temporal-controlnet/wandb/run-20241128_230708-ztiv9q6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-monkey-74
wandb: ⭐️ View project at https://wandb.ai/sjxu_gamma/SVD_Con_Mul
wandb: 🚀 View run at https://wandb.ai/sjxu_gamma/SVD_Con_Mul/runs/ztiv9q6l
11/28/2024 23:07:11 - INFO - __main__ - ***** Running training *****
11/28/2024 23:07:11 - INFO - __main__ -   Num examples = 4728
11/28/2024 23:07:11 - INFO - __main__ -   Num Epochs = 30
11/28/2024 23:07:11 - INFO - __main__ -   Instantaneous batch size per device = 2
11/28/2024 23:07:11 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 64
11/28/2024 23:07:11 - INFO - __main__ -   Gradient Accumulation steps = 8
11/28/2024 23:07:11 - INFO - __main__ -   Total optimization steps = 2220
  0%|          | 0/2220 [00:00<?, ?it/s]Steps:   0%|          | 0/2220 [00:00<?, ?it/s]/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
Steps:   0%|          | 0/2220 [00:26<?, ?it/s, lr=0.0001, step_loss=0.194]Steps:   0%|          | 0/2220 [00:29<?, ?it/s, lr=0.0001, step_loss=0.143]Steps:   0%|          | 0/2220 [00:31<?, ?it/s, lr=0.0001, step_loss=0.174]Steps:   0%|          | 0/2220 [00:33<?, ?it/s, lr=0.0001, step_loss=0.213]Steps:   0%|          | 0/2220 [00:35<?, ?it/s, lr=0.0001, step_loss=0.198]Steps:   0%|          | 0/2220 [00:37<?, ?it/s, lr=0.0001, step_loss=0.125]Steps:   0%|          | 0/2220 [00:39<?, ?it/s, lr=0.0001, step_loss=0.441]Steps:   0%|          | 1/2220 [00:42<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.441]11/28/2024 23:07:53 - INFO - __main__ - Running validation... 
 Generating 1 videos.
/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
{'controlnet'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s][ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-video-diffusion-img2vid.
{'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-video-diffusion-img2vid.
Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00, 61.11it/s]
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
Steps:   0%|          | 1/2220 [01:01<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.102]/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
Steps:   0%|          | 1/2220 [01:02<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.228]Steps:   0%|          | 1/2220 [01:04<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.237]Steps:   0%|          | 1/2220 [01:06<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.256]Steps:   0%|          | 1/2220 [01:08<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.192]Steps:   0%|          | 1/2220 [01:10<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.0972]Steps:   0%|          | 1/2220 [01:11<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.125] Steps:   0%|          | 1/2220 [01:13<25:59:09, 42.16s/it, lr=0.0001, step_loss=0.311]Steps:   0%|          | 2/2220 [01:16<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.311]Steps:   0%|          | 2/2220 [01:16<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.212]Steps:   0%|          | 2/2220 [01:18<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.0872]Steps:   0%|          | 2/2220 [01:20<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.32]  Steps:   0%|          | 2/2220 [01:22<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.376]Steps:   0%|          | 2/2220 [01:23<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.16] Steps:   0%|          | 2/2220 [01:25<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.215]Steps:   0%|          | 2/2220 [01:27<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.454]Steps:   0%|          | 2/2220 [01:29<23:03:26, 37.42s/it, lr=0.0001, step_loss=0.188]Steps:   0%|          | 3/2220 [01:32<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.188]Steps:   0%|          | 3/2220 [01:32<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.211]Steps:   0%|          | 3/2220 [01:33<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.165]Steps:   0%|          | 3/2220 [01:35<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.15] Steps:   0%|          | 3/2220 [01:37<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.325]Steps:   0%|          | 3/2220 [01:39<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.478]Steps:   0%|          | 3/2220 [01:41<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.0819]Steps:   0%|          | 3/2220 [01:43<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.121] Steps:   0%|          | 3/2220 [01:45<16:57:36, 27.54s/it, lr=0.0001, step_loss=0.138]Steps:   0%|          | 4/2220 [01:47<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.138]Steps:   0%|          | 4/2220 [01:47<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.145]Steps:   0%|          | 4/2220 [01:49<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.096]Steps:   0%|          | 4/2220 [01:51<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.279]Steps:   0%|          | 4/2220 [01:53<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.222]Steps:   0%|          | 4/2220 [01:55<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.152]Steps:   0%|          | 4/2220 [01:57<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.0925]Steps:   0%|          | 4/2220 [01:58<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.129] Steps:   0%|          | 4/2220 [02:00<14:01:02, 22.77s/it, lr=0.0001, step_loss=0.12] Steps:   0%|          | 5/2220 [02:02<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.12]Steps:   0%|          | 5/2220 [02:03<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.103]Steps:   0%|          | 5/2220 [02:04<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.0701]Steps:   0%|          | 5/2220 [02:06<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.519] Steps:   0%|          | 5/2220 [02:08<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.125]Steps:   0%|          | 5/2220 [02:11<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.392]Steps:   0%|          | 5/2220 [02:12<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.189]Steps:   0%|          | 5/2220 [02:14<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.0822]Steps:   0%|          | 5/2220 [02:16<12:23:42, 20.15s/it, lr=0.0001, step_loss=0.109] Steps:   0%|          | 6/2220 [02:18<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.109]Steps:   0%|          | 6/2220 [02:19<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.548]Steps:   0%|          | 6/2220 [02:20<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.104]Steps:   0%|          | 6/2220 [02:22<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.152]Steps:   0%|          | 6/2220 [02:24<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.363]Steps:   0%|          | 6/2220 [02:26<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.16] Steps:   0%|          | 6/2220 [02:28<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.209]Steps:   0%|          | 6/2220 [02:30<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.141]Steps:   0%|          | 6/2220 [02:32<11:30:46, 18.72s/it, lr=0.0001, step_loss=0.117]Steps:   0%|          | 7/2220 [02:34<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.117]Steps:   0%|          | 7/2220 [02:34<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.123]Steps:   0%|          | 7/2220 [02:36<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.163]Steps:   0%|          | 7/2220 [02:38<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.299]Steps:   0%|          | 7/2220 [02:40<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.112]Steps:   0%|          | 7/2220 [02:42<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.18] Steps:   0%|          | 7/2220 [02:44<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.149]Steps:   0%|          | 7/2220 [02:46<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.206]Steps:   0%|          | 7/2220 [02:48<10:53:44, 17.72s/it, lr=0.0001, step_loss=0.366]Steps:   0%|          | 8/2220 [02:50<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.366]Steps:   0%|          | 8/2220 [02:50<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.184]Steps:   0%|          | 8/2220 [02:52<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.265]Steps:   0%|          | 8/2220 [02:53<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.277]Steps:   0%|          | 8/2220 [02:55<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.38] Steps:   0%|          | 8/2220 [02:57<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.251]Steps:   0%|          | 8/2220 [02:59<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.332]Steps:   0%|          | 8/2220 [03:01<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.139]Steps:   0%|          | 8/2220 [03:03<10:28:38, 17.05s/it, lr=0.0001, step_loss=0.102]Steps:   0%|          | 9/2220 [03:06<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.102]Steps:   0%|          | 9/2220 [03:06<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.346]Steps:   0%|          | 9/2220 [03:08<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.363]Steps:   0%|          | 9/2220 [03:09<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.097]Steps:   0%|          | 9/2220 [03:11<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.156]Steps:   0%|          | 9/2220 [03:13<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.0801]Steps:   0%|          | 9/2220 [03:15<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.178] Steps:   0%|          | 9/2220 [03:17<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.124]Steps:   0%|          | 9/2220 [03:19<10:15:45, 16.71s/it, lr=0.0001, step_loss=0.053]Steps:   0%|          | 10/2220 [03:21<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.053]Steps:   0%|          | 10/2220 [03:21<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.123]Steps:   0%|          | 10/2220 [03:23<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.0852]Steps:   0%|          | 10/2220 [03:25<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.145] Steps:   0%|          | 10/2220 [03:27<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.175]Steps:   0%|          | 10/2220 [03:29<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.337]Steps:   0%|          | 10/2220 [03:31<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.581]Steps:   0%|          | 10/2220 [03:32<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.0722]Steps:   0%|          | 10/2220 [03:35<10:01:05, 16.32s/it, lr=0.0001, step_loss=0.342] Steps:   0%|          | 11/2220 [03:37<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.342] Steps:   0%|          | 11/2220 [03:37<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.171]Steps:   0%|          | 11/2220 [03:39<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.103]Steps:   0%|          | 11/2220 [03:40<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.174]Steps:   0%|          | 11/2220 [03:42<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.61] Steps:   0%|          | 11/2220 [03:44<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.154]Steps:   0%|          | 11/2220 [03:46<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.0922]Steps:   0%|          | 11/2220 [03:48<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.106] Steps:   0%|          | 11/2220 [03:50<9:52:40, 16.10s/it, lr=0.0001, step_loss=0.0662]Steps:   1%|          | 12/2220 [03:53<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.0662]Steps:   1%|          | 12/2220 [03:53<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.32]  Steps:   1%|          | 12/2220 [03:54<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.11]Steps:   1%|          | 12/2220 [03:56<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.319]Steps:   1%|          | 12/2220 [03:58<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.165]Steps:   1%|          | 12/2220 [04:00<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.11] Steps:   1%|          | 12/2220 [04:02<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.224]Steps:   1%|          | 12/2220 [04:04<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.197]Steps:   1%|          | 12/2220 [04:06<9:48:59, 16.01s/it, lr=0.0001, step_loss=0.215]Steps:   1%|          | 13/2220 [04:08<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.215]Steps:   1%|          | 13/2220 [04:08<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.215]Steps:   1%|          | 13/2220 [04:10<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.386]Steps:   1%|          | 13/2220 [04:12<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.082]Steps:   1%|          | 13/2220 [04:14<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.183]Steps:   1%|          | 13/2220 [04:16<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.176]Steps:   1%|          | 13/2220 [04:18<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.156]Steps:   1%|          | 13/2220 [04:20<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.212]Steps:   1%|          | 13/2220 [04:22<9:44:35, 15.89s/it, lr=0.0001, step_loss=0.0771]Steps:   1%|          | 14/2220 [04:24<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.0771]Steps:   1%|          | 14/2220 [04:24<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.0953]Steps:   1%|          | 14/2220 [04:26<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.117] Steps:   1%|          | 14/2220 [04:28<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.354]Steps:   1%|          | 14/2220 [04:29<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.175]Steps:   1%|          | 14/2220 [04:31<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.498]Steps:   1%|          | 14/2220 [04:33<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.24] Steps:   1%|          | 14/2220 [04:35<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.098]Steps:   1%|          | 14/2220 [04:37<9:42:06, 15.83s/it, lr=0.0001, step_loss=0.157]Steps:   1%|          | 15/2220 [04:39<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.157]Steps:   1%|          | 15/2220 [04:40<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.173]Steps:   1%|          | 15/2220 [04:41<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.163]Steps:   1%|          | 15/2220 [04:43<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.175]Steps:   1%|          | 15/2220 [04:45<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.0629]Steps:   1%|          | 15/2220 [04:47<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.14]  Steps:   1%|          | 15/2220 [04:49<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.116]Steps:   1%|          | 15/2220 [04:51<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.11] Steps:   1%|          | 15/2220 [04:53<9:39:32, 15.77s/it, lr=0.0001, step_loss=0.369]Steps:   1%|          | 16/2220 [04:56<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.369]Steps:   1%|          | 16/2220 [04:56<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.155]Steps:   1%|          | 16/2220 [04:58<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.0789]Steps:   1%|          | 16/2220 [04:59<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.0772]Steps:   1%|          | 16/2220 [05:01<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.117] Steps:   1%|          | 16/2220 [05:03<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.103]Steps:   1%|          | 16/2220 [05:05<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.295]Steps:   1%|          | 16/2220 [05:07<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.359]Steps:   1%|          | 16/2220 [05:09<9:45:43, 15.95s/it, lr=0.0001, step_loss=0.251]Steps:   1%|          | 17/2220 [05:11<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.251]Steps:   1%|          | 17/2220 [05:11<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.307]Steps:   1%|          | 17/2220 [05:13<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.343]Steps:   1%|          | 17/2220 [05:15<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.0928]Steps:   1%|          | 17/2220 [05:17<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.171] Steps:   1%|          | 17/2220 [05:19<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.115]Steps:   1%|          | 17/2220 [05:21<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.173]Steps:   1%|          | 17/2220 [05:23<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.151]Steps:   1%|          | 17/2220 [05:25<9:40:00, 15.80s/it, lr=0.0001, step_loss=0.167]Steps:   1%|          | 18/2220 [05:27<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.167]Steps:   1%|          | 18/2220 [05:27<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.171]Steps:   1%|          | 18/2220 [05:29<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.161]Steps:   1%|          | 18/2220 [05:31<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.163]Steps:   1%|          | 18/2220 [05:33<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.153]Steps:   1%|          | 18/2220 [05:35<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.506]Steps:   1%|          | 18/2220 [05:37<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.127]Steps:   1%|          | 18/2220 [05:39<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.0795]Steps:   1%|          | 18/2220 [05:41<9:39:29, 15.79s/it, lr=0.0001, step_loss=0.111] Steps:   1%|          | 19/2220 [05:43<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.111]Steps:   1%|          | 19/2220 [05:43<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.202]Steps:   1%|          | 19/2220 [05:45<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.305]Steps:   1%|          | 19/2220 [05:47<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.0923]Steps:   1%|          | 19/2220 [05:49<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.242] Steps:   1%|          | 19/2220 [05:51<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.137]Steps:   1%|          | 19/2220 [05:52<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.0773]Steps:   1%|          | 19/2220 [05:54<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.19]  Steps:   1%|          | 19/2220 [05:56<9:41:27, 15.85s/it, lr=0.0001, step_loss=0.0927]Steps:   1%|          | 20/2220 [05:58<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.0927]/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
11/28/2024 23:14:41 - INFO - __main__ - Step 20: Test Loss = 0.1926
Steps:   1%|          | 20/2220 [07:30<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.119] Steps:   1%|          | 20/2220 [07:32<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.398]Steps:   1%|          | 20/2220 [07:34<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.177]Steps:   1%|          | 20/2220 [07:35<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.526]Steps:   1%|          | 20/2220 [07:37<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.0934]Steps:   1%|          | 20/2220 [07:39<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.128] Steps:   1%|          | 20/2220 [07:41<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.204]Steps:   1%|          | 20/2220 [07:43<9:36:19, 15.72s/it, lr=0.0001, step_loss=0.186]Steps:   1%|          | 21/2220 [07:45<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.186]Steps:   1%|          | 21/2220 [07:45<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.215]Steps:   1%|          | 21/2220 [07:47<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.488]Steps:   1%|          | 21/2220 [07:49<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.22] Steps:   1%|          | 21/2220 [07:51<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.057]Steps:   1%|          | 21/2220 [07:53<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.156]Steps:   1%|          | 21/2220 [07:55<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.378]Steps:   1%|          | 21/2220 [07:57<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.304]Steps:   1%|          | 21/2220 [07:59<26:17:54, 43.05s/it, lr=0.0001, step_loss=0.47] Steps:   1%|          | 22/2220 [08:01<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.47]Steps:   1%|          | 22/2220 [08:01<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.231]Steps:   1%|          | 22/2220 [08:03<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.148]Steps:   1%|          | 22/2220 [08:04<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.108]Steps:   1%|          | 22/2220 [08:06<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.3]  Steps:   1%|          | 22/2220 [08:08<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.125]Steps:   1%|          | 22/2220 [08:10<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.089]Steps:   1%|          | 22/2220 [08:12<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.183]Steps:   1%|          | 22/2220 [08:14<21:15:07, 34.81s/it, lr=0.0001, step_loss=0.117]Steps:   1%|          | 23/2220 [08:16<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.117]Steps:   1%|          | 23/2220 [08:16<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.198]Steps:   1%|          | 23/2220 [08:18<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.0996]Steps:   1%|          | 23/2220 [08:21<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.137] Steps:   1%|          | 23/2220 [08:23<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.0981]Steps:   1%|          | 23/2220 [08:24<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.119] Steps:   1%|          | 23/2220 [08:27<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.184]Steps:   1%|          | 23/2220 [08:29<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.293]Steps:   1%|          | 23/2220 [08:30<17:43:27, 29.04s/it, lr=0.0001, step_loss=0.114]Steps:   1%|          | 24/2220 [08:33<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.114]Steps:   1%|          | 24/2220 [08:33<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.135]Steps:   1%|          | 24/2220 [08:34<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.212]Steps:   1%|          | 24/2220 [08:36<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.148]Steps:   1%|          | 24/2220 [08:39<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.168]Steps:   1%|          | 24/2220 [08:40<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.312]Steps:   1%|          | 24/2220 [08:42<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.146]Steps:   1%|          | 24/2220 [08:44<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.124]Steps:   1%|          | 24/2220 [08:46<15:21:22, 25.17s/it, lr=0.0001, step_loss=0.262]Steps:   1%|          | 25/2220 [08:49<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.262]Steps:   1%|          | 25/2220 [08:49<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.378]Steps:   1%|          | 25/2220 [08:50<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.148]Steps:   1%|          | 25/2220 [08:52<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.121]Steps:   1%|          | 25/2220 [08:54<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.135]Steps:   1%|          | 25/2220 [08:56<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.507]Steps:   1%|          | 25/2220 [08:58<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.202]Steps:   1%|          | 25/2220 [09:00<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.16] Steps:   1%|          | 25/2220 [09:02<13:40:03, 22.42s/it, lr=0.0001, step_loss=0.206]Steps:   1%|          | 26/2220 [09:04<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.206]Steps:   1%|          | 26/2220 [09:04<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.267]Steps:   1%|          | 26/2220 [09:06<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.0974]Steps:   1%|          | 26/2220 [09:08<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.228] Steps:   1%|          | 26/2220 [09:10<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.113]Steps:   1%|          | 26/2220 [09:12<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.167]Steps:   1%|          | 26/2220 [09:14<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.247]Steps:   1%|          | 26/2220 [09:16<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.234]Steps:   1%|          | 26/2220 [09:17<12:24:15, 20.35s/it, lr=0.0001, step_loss=0.535]Steps:   1%|          | 27/2220 [09:20<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.535]Steps:   1%|          | 27/2220 [09:20<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.15] Steps:   1%|          | 27/2220 [09:22<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.524]Steps:   1%|          | 27/2220 [09:23<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.117]Steps:   1%|          | 27/2220 [09:25<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.133]Steps:   1%|          | 27/2220 [09:27<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.29] Steps:   1%|          | 27/2220 [09:29<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.296]Steps:   1%|          | 27/2220 [09:31<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.413]Steps:   1%|          | 27/2220 [09:33<11:31:05, 18.91s/it, lr=0.0001, step_loss=0.14] Steps:   1%|▏         | 28/2220 [09:35<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.14]Steps:   1%|▏         | 28/2220 [09:35<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.0904]Steps:   1%|▏         | 28/2220 [09:37<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.0994]Steps:   1%|▏         | 28/2220 [09:39<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.109] Steps:   1%|▏         | 28/2220 [09:41<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.0984]Steps:   1%|▏         | 28/2220 [09:43<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.21]  Steps:   1%|▏         | 28/2220 [09:45<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.233]Steps:   1%|▏         | 28/2220 [09:47<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.374]Steps:   1%|▏         | 28/2220 [09:48<10:54:36, 17.92s/it, lr=0.0001, step_loss=0.495]Steps:   1%|▏         | 29/2220 [09:51<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.495]Steps:   1%|▏         | 29/2220 [09:51<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.366]Steps:   1%|▏         | 29/2220 [09:53<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.123]Steps:   1%|▏         | 29/2220 [09:54<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.158]Steps:   1%|▏         | 29/2220 [09:56<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.109]Steps:   1%|▏         | 29/2220 [09:58<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.142]Steps:   1%|▏         | 29/2220 [10:00<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.272]Steps:   1%|▏         | 29/2220 [10:02<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.117]Steps:   1%|▏         | 29/2220 [10:05<10:27:30, 17.18s/it, lr=0.0001, step_loss=0.116]Steps:   1%|▏         | 30/2220 [10:07<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.116]Steps:   1%|▏         | 30/2220 [10:07<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.174]Steps:   1%|▏         | 30/2220 [10:09<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.123]Steps:   1%|▏         | 30/2220 [10:11<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.103]Steps:   1%|▏         | 30/2220 [10:13<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.255]Steps:   1%|▏         | 30/2220 [10:14<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.0884]Steps:   1%|▏         | 30/2220 [10:17<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.295] Steps:   1%|▏         | 30/2220 [10:18<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.153]Steps:   1%|▏         | 30/2220 [10:21<10:18:42, 16.95s/it, lr=0.0001, step_loss=0.219]Steps:   1%|▏         | 31/2220 [10:23<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.219]Steps:   1%|▏         | 31/2220 [10:23<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.181]Steps:   1%|▏         | 31/2220 [10:25<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.36] Steps:   1%|▏         | 31/2220 [10:26<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.294]Steps:   1%|▏         | 31/2220 [10:28<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.166]Steps:   1%|▏         | 31/2220 [10:30<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.0916]Steps:   1%|▏         | 31/2220 [10:32<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.19]  Steps:   1%|▏         | 31/2220 [10:34<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.108]Steps:   1%|▏         | 31/2220 [10:36<10:03:36, 16.54s/it, lr=0.0001, step_loss=0.533]Steps:   1%|▏         | 32/2220 [10:38<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.533] Steps:   1%|▏         | 32/2220 [10:38<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.0806]Steps:   1%|▏         | 32/2220 [10:40<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.151] Steps:   1%|▏         | 32/2220 [10:42<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.132]Steps:   1%|▏         | 32/2220 [10:44<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.192]Steps:   1%|▏         | 32/2220 [10:46<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.402]Steps:   1%|▏         | 32/2220 [10:48<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.156]Steps:   1%|▏         | 32/2220 [10:50<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.0671]Steps:   1%|▏         | 32/2220 [10:52<9:52:18, 16.24s/it, lr=0.0001, step_loss=0.17]  Steps:   1%|▏         | 33/2220 [10:54<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.17]Steps:   1%|▏         | 33/2220 [10:54<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.0968]Steps:   1%|▏         | 33/2220 [10:56<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.136] Steps:   1%|▏         | 33/2220 [10:58<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.482]Steps:   1%|▏         | 33/2220 [11:00<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.113]Steps:   1%|▏         | 33/2220 [11:02<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.285]Steps:   1%|▏         | 33/2220 [11:03<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.163]Steps:   1%|▏         | 33/2220 [11:05<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.171]Steps:   1%|▏         | 33/2220 [11:07<9:45:23, 16.06s/it, lr=0.0001, step_loss=0.0785]Steps:   2%|▏         | 34/2220 [11:09<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.0785]Steps:   2%|▏         | 34/2220 [11:09<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.167] Steps:   2%|▏         | 34/2220 [11:11<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.313]Steps:   2%|▏         | 34/2220 [11:13<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.15] Steps:   2%|▏         | 34/2220 [11:15<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.138]Steps:   2%|▏         | 34/2220 [11:17<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.477]Steps:   2%|▏         | 34/2220 [11:19<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.169]Steps:   2%|▏         | 34/2220 [11:21<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.107]Steps:   2%|▏         | 34/2220 [11:23<9:39:17, 15.90s/it, lr=0.0001, step_loss=0.265]Steps:   2%|▏         | 35/2220 [11:25<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.265]Steps:   2%|▏         | 35/2220 [11:25<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.196]Steps:   2%|▏         | 35/2220 [11:27<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.139]Steps:   2%|▏         | 35/2220 [11:29<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.0921]Steps:   2%|▏         | 35/2220 [11:31<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.238] Steps:   2%|▏         | 35/2220 [11:33<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.0717]Steps:   2%|▏         | 35/2220 [11:35<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.21]  Steps:   2%|▏         | 35/2220 [11:37<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.0942]Steps:   2%|▏         | 35/2220 [11:39<9:36:27, 15.83s/it, lr=0.0001, step_loss=0.314] Steps:   2%|▏         | 36/2220 [11:41<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.314]Steps:   2%|▏         | 36/2220 [11:41<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.388]Steps:   2%|▏         | 36/2220 [11:43<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.15] Steps:   2%|▏         | 36/2220 [11:45<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.123]Steps:   2%|▏         | 36/2220 [11:46<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.132]Steps:   2%|▏         | 36/2220 [11:48<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.112]Steps:   2%|▏         | 36/2220 [11:50<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.247]Steps:   2%|▏         | 36/2220 [11:53<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.077]Steps:   2%|▏         | 36/2220 [11:55<9:35:15, 15.80s/it, lr=0.0001, step_loss=0.352]Steps:   2%|▏         | 37/2220 [11:57<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.352]Steps:   2%|▏         | 37/2220 [11:57<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.25] Steps:   2%|▏         | 37/2220 [11:59<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.208]Steps:   2%|▏         | 37/2220 [12:00<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.197]Steps:   2%|▏         | 37/2220 [12:02<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.369]Steps:   2%|▏         | 37/2220 [12:04<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.488]Steps:   2%|▏         | 37/2220 [12:06<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.342]Steps:   2%|▏         | 37/2220 [12:08<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.119]Steps:   2%|▏         | 37/2220 [12:10<9:37:47, 15.88s/it, lr=0.0001, step_loss=0.0996]Steps:   2%|▏         | 38/2220 [12:12<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.0996]Steps:   2%|▏         | 38/2220 [12:12<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.324] Steps:   2%|▏         | 38/2220 [12:14<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.099]Steps:   2%|▏         | 38/2220 [12:16<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.169]Steps:   2%|▏         | 38/2220 [12:18<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.123]Steps:   2%|▏         | 38/2220 [12:20<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.234]Steps:   2%|▏         | 38/2220 [12:22<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.194]Steps:   2%|▏         | 38/2220 [12:24<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.572]Steps:   2%|▏         | 38/2220 [12:26<9:32:50, 15.75s/it, lr=0.0001, step_loss=0.149]Steps:   2%|▏         | 39/2220 [12:28<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.149]Steps:   2%|▏         | 39/2220 [12:28<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.344]Steps:   2%|▏         | 39/2220 [12:30<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.23] Steps:   2%|▏         | 39/2220 [12:32<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.0901]Steps:   2%|▏         | 39/2220 [12:34<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.543] Steps:   2%|▏         | 39/2220 [12:35<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.276]Steps:   2%|▏         | 39/2220 [12:37<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.0646]Steps:   2%|▏         | 39/2220 [12:39<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.524] Steps:   2%|▏         | 39/2220 [12:41<9:31:56, 15.73s/it, lr=0.0001, step_loss=0.157]Steps:   2%|▏         | 40/2220 [12:44<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.157]11/28/2024 23:21:26 - INFO - __main__ - Step 40: Test Loss = 0.1854
Steps:   2%|▏         | 40/2220 [14:15<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.151]Steps:   2%|▏         | 40/2220 [14:16<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.298]Steps:   2%|▏         | 40/2220 [14:18<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.0709]Steps:   2%|▏         | 40/2220 [14:20<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.551] Steps:   2%|▏         | 40/2220 [14:22<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.269]Steps:   2%|▏         | 40/2220 [14:24<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.117]Steps:   2%|▏         | 40/2220 [14:26<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.195]Steps:   2%|▏         | 40/2220 [14:27<9:28:52, 15.66s/it, lr=0.0001, step_loss=0.37] Steps:   2%|▏         | 41/2220 [14:30<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.37]Steps:   2%|▏         | 41/2220 [14:30<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.0989]Steps:   2%|▏         | 41/2220 [14:32<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.529] Steps:   2%|▏         | 41/2220 [14:34<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.131]Steps:   2%|▏         | 41/2220 [14:35<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.275]Steps:   2%|▏         | 41/2220 [14:37<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.333]Steps:   2%|▏         | 41/2220 [14:39<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.142]Steps:   2%|▏         | 41/2220 [14:41<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.184]Steps:   2%|▏         | 41/2220 [14:43<25:55:27, 42.83s/it, lr=0.0001, step_loss=0.205]Steps:   2%|▏         | 42/2220 [14:45<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.205]Steps:   2%|▏         | 42/2220 [14:45<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.107]Steps:   2%|▏         | 42/2220 [14:48<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.207]Steps:   2%|▏         | 42/2220 [14:49<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.138]Steps:   2%|▏         | 42/2220 [14:51<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.209]Steps:   2%|▏         | 42/2220 [14:53<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.211]Steps:   2%|▏         | 42/2220 [14:55<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.125]Steps:   2%|▏         | 42/2220 [14:57<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.124]Steps:   2%|▏         | 42/2220 [14:59<20:57:54, 34.65s/it, lr=0.0001, step_loss=0.172]Steps:   2%|▏         | 43/2220 [15:01<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.172]Steps:   2%|▏         | 43/2220 [15:01<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.116]Steps:   2%|▏         | 43/2220 [15:03<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.136]Steps:   2%|▏         | 43/2220 [15:05<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.317]Steps:   2%|▏         | 43/2220 [15:07<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.192]Steps:   2%|▏         | 43/2220 [15:09<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.254]Steps:   2%|▏         | 43/2220 [15:11<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.12] Steps:   2%|▏         | 43/2220 [15:13<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.229]Steps:   2%|▏         | 43/2220 [15:15<17:31:50, 28.99s/it, lr=0.0001, step_loss=0.0979]Steps:   2%|▏         | 44/2220 [15:17<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.0979]Steps:   2%|▏         | 44/2220 [15:17<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.136] Steps:   2%|▏         | 44/2220 [15:19<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.351]Steps:   2%|▏         | 44/2220 [15:21<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.231]Steps:   2%|▏         | 44/2220 [15:23<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.172]Steps:   2%|▏         | 44/2220 [15:25<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.324]Steps:   2%|▏         | 44/2220 [15:27<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.395]Steps:   2%|▏         | 44/2220 [15:29<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.425]Steps:   2%|▏         | 44/2220 [15:31<15:10:48, 25.11s/it, lr=0.0001, step_loss=0.0773]Steps:   2%|▏         | 45/2220 [15:33<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.0773]Steps:   2%|▏         | 45/2220 [15:33<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.18]  Steps:   2%|▏         | 45/2220 [15:35<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.135]Steps:   2%|▏         | 45/2220 [15:37<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.185]Steps:   2%|▏         | 45/2220 [15:38<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.264]Steps:   2%|▏         | 45/2220 [15:40<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.202]Steps:   2%|▏         | 45/2220 [15:42<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.143]Steps:   2%|▏         | 45/2220 [15:44<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.181]Steps:   2%|▏         | 45/2220 [15:46<13:27:36, 22.28s/it, lr=0.0001, step_loss=0.522]Steps:   2%|▏         | 46/2220 [15:48<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.522]Steps:   2%|▏         | 46/2220 [15:49<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.295]Steps:   2%|▏         | 46/2220 [15:50<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.194]Steps:   2%|▏         | 46/2220 [15:52<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.515]Steps:   2%|▏         | 46/2220 [15:54<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.149]Steps:   2%|▏         | 46/2220 [15:56<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.156]Steps:   2%|▏         | 46/2220 [15:58<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.0964]Steps:   2%|▏         | 46/2220 [16:00<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.0849]Steps:   2%|▏         | 46/2220 [16:02<12:15:23, 20.30s/it, lr=0.0001, step_loss=0.0875]Steps:   2%|▏         | 47/2220 [16:04<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.0875]Steps:   2%|▏         | 47/2220 [16:04<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.121] Steps:   2%|▏         | 47/2220 [16:06<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.0891]Steps:   2%|▏         | 47/2220 [16:08<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.303] Steps:   2%|▏         | 47/2220 [16:10<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.272]Steps:   2%|▏         | 47/2220 [16:12<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.102]Steps:   2%|▏         | 47/2220 [16:14<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.523]Steps:   2%|▏         | 47/2220 [16:15<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.066]Steps:   2%|▏         | 47/2220 [16:17<11:23:52, 18.88s/it, lr=0.0001, step_loss=0.116]Steps:   2%|▏         | 48/2220 [16:20<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.116]Steps:   2%|▏         | 48/2220 [16:20<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.417]Steps:   2%|▏         | 48/2220 [16:22<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.372]Steps:   2%|▏         | 48/2220 [16:23<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.111]Steps:   2%|▏         | 48/2220 [16:26<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.212]Steps:   2%|▏         | 48/2220 [16:28<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.273]Steps:   2%|▏         | 48/2220 [16:30<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.106]Steps:   2%|▏         | 48/2220 [16:31<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.106]Steps:   2%|▏         | 48/2220 [16:33<10:47:00, 17.87s/it, lr=0.0001, step_loss=0.269]Steps:   2%|▏         | 49/2220 [16:36<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.269]Steps:   2%|▏         | 49/2220 [16:36<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.505]Steps:   2%|▏         | 49/2220 [16:38<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.148]Steps:   2%|▏         | 49/2220 [16:39<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.28] Steps:   2%|▏         | 49/2220 [16:41<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.31]Steps:   2%|▏         | 49/2220 [16:43<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.217]Steps:   2%|▏         | 49/2220 [16:45<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.176]Steps:   2%|▏         | 49/2220 [16:47<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.122]Steps:   2%|▏         | 49/2220 [16:49<10:27:00, 17.33s/it, lr=0.0001, step_loss=0.149]Steps:   2%|▏         | 50/2220 [16:51<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.149]Steps:   2%|▏         | 50/2220 [16:51<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.273]Steps:   2%|▏         | 50/2220 [16:53<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.362]Steps:   2%|▏         | 50/2220 [16:55<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.161]Steps:   2%|▏         | 50/2220 [16:57<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.382]Steps:   2%|▏         | 50/2220 [16:59<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.44] Steps:   2%|▏         | 50/2220 [17:01<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.112]Steps:   2%|▏         | 50/2220 [17:03<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.104]Steps:   2%|▏         | 50/2220 [17:05<10:09:38, 16.86s/it, lr=0.0001, step_loss=0.122]Steps:   2%|▏         | 51/2220 [17:07<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.122] Steps:   2%|▏         | 51/2220 [17:07<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.0789]Steps:   2%|▏         | 51/2220 [17:09<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.0876]Steps:   2%|▏         | 51/2220 [17:11<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.248] Steps:   2%|▏         | 51/2220 [17:13<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.422]Steps:   2%|▏         | 51/2220 [17:15<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.236]Steps:   2%|▏         | 51/2220 [17:17<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.148]Steps:   2%|▏         | 51/2220 [17:19<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.117]Steps:   2%|▏         | 51/2220 [17:21<9:59:32, 16.58s/it, lr=0.0001, step_loss=0.153]Steps:   2%|▏         | 52/2220 [17:23<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.153]Steps:   2%|▏         | 52/2220 [17:23<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.544]Steps:   2%|▏         | 52/2220 [17:25<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.135]Steps:   2%|▏         | 52/2220 [17:27<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.183]Steps:   2%|▏         | 52/2220 [17:28<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.285]Steps:   2%|▏         | 52/2220 [17:30<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.131]Steps:   2%|▏         | 52/2220 [17:32<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.139]Steps:   2%|▏         | 52/2220 [17:34<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.173]Steps:   2%|▏         | 52/2220 [17:36<9:46:44, 16.24s/it, lr=0.0001, step_loss=0.341]Steps:   2%|▏         | 53/2220 [17:39<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.341]Steps:   2%|▏         | 53/2220 [17:39<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.521]Steps:   2%|▏         | 53/2220 [17:41<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.18] Steps:   2%|▏         | 53/2220 [17:42<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.17]Steps:   2%|▏         | 53/2220 [17:44<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.0776]Steps:   2%|▏         | 53/2220 [17:46<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.105] Steps:   2%|▏         | 53/2220 [17:48<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.121]Steps:   2%|▏         | 53/2220 [17:50<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.0724]Steps:   2%|▏         | 53/2220 [17:52<9:41:43, 16.11s/it, lr=0.0001, step_loss=0.15]  Steps:   2%|▏         | 54/2220 [17:54<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.15]Steps:   2%|▏         | 54/2220 [17:54<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.121]Steps:   2%|▏         | 54/2220 [17:56<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.331]Steps:   2%|▏         | 54/2220 [17:58<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.335]Steps:   2%|▏         | 54/2220 [18:00<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.134]Steps:   2%|▏         | 54/2220 [18:02<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.181]Steps:   2%|▏         | 54/2220 [18:04<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.216]Steps:   2%|▏         | 54/2220 [18:06<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.238]Steps:   2%|▏         | 54/2220 [18:08<9:35:32, 15.94s/it, lr=0.0001, step_loss=0.536]Steps:   2%|▏         | 55/2220 [18:10<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.536]Steps:   2%|▏         | 55/2220 [18:10<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.417]Steps:   2%|▏         | 55/2220 [18:12<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.0652]Steps:   2%|▏         | 55/2220 [18:14<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.134] Steps:   2%|▏         | 55/2220 [18:16<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.485]Steps:   2%|▏         | 55/2220 [18:18<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.141]Steps:   2%|▏         | 55/2220 [18:20<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.122]Steps:   2%|▏         | 55/2220 [18:22<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.205]Steps:   2%|▏         | 55/2220 [18:24<9:36:43, 15.98s/it, lr=0.0001, step_loss=0.116]Steps:   3%|▎         | 56/2220 [18:26<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.116]Steps:   3%|▎         | 56/2220 [18:26<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.136]Steps:   3%|▎         | 56/2220 [18:28<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.131]Steps:   3%|▎         | 56/2220 [18:30<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.122]Steps:   3%|▎         | 56/2220 [18:32<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.0808]Steps:   3%|▎         | 56/2220 [18:34<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.142] Steps:   3%|▎         | 56/2220 [18:36<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.117]Steps:   3%|▎         | 56/2220 [18:37<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.353]Steps:   3%|▎         | 56/2220 [18:39<9:34:30, 15.93s/it, lr=0.0001, step_loss=0.118]Steps:   3%|▎         | 57/2220 [18:42<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.118]Steps:   3%|▎         | 57/2220 [18:42<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.273]Steps:   3%|▎         | 57/2220 [18:44<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.164]Steps:   3%|▎         | 57/2220 [18:46<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.171]Steps:   3%|▎         | 57/2220 [18:48<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.153]Steps:   3%|▎         | 57/2220 [18:50<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.131]Steps:   3%|▎         | 57/2220 [18:51<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.292]Steps:   3%|▎         | 57/2220 [18:53<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.205]Steps:   3%|▎         | 57/2220 [18:55<9:34:37, 15.94s/it, lr=0.0001, step_loss=0.202]Steps:   3%|▎         | 58/2220 [18:58<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.202]Steps:   3%|▎         | 58/2220 [18:58<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.131]Steps:   3%|▎         | 58/2220 [18:59<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.154]Steps:   3%|▎         | 58/2220 [19:01<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.191]Steps:   3%|▎         | 58/2220 [19:03<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.133]Steps:   3%|▎         | 58/2220 [19:05<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.0728]Steps:   3%|▎         | 58/2220 [19:07<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.105] Steps:   3%|▎         | 58/2220 [19:09<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.221]Steps:   3%|▎         | 58/2220 [19:11<9:30:13, 15.82s/it, lr=0.0001, step_loss=0.187]Steps:   3%|▎         | 59/2220 [19:13<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.187]Steps:   3%|▎         | 59/2220 [19:13<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.149]Steps:   3%|▎         | 59/2220 [19:15<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.355]Steps:   3%|▎         | 59/2220 [19:17<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.325]Steps:   3%|▎         | 59/2220 [19:19<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.135]Steps:   3%|▎         | 59/2220 [19:21<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.137]Steps:   3%|▎         | 59/2220 [19:23<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.284]Steps:   3%|▎         | 59/2220 [19:25<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.101]Steps:   3%|▎         | 59/2220 [19:27<9:29:50, 15.82s/it, lr=0.0001, step_loss=0.277]Steps:   3%|▎         | 60/2220 [19:29<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.277]11/28/2024 23:28:10 - INFO - __main__ - Step 60: Test Loss = 0.1848
Steps:   3%|▎         | 60/2220 [20:59<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.24] Steps:   3%|▎         | 60/2220 [21:02<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.134]Steps:   3%|▎         | 60/2220 [21:04<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.512]Steps:   3%|▎         | 60/2220 [21:06<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.287]Steps:   3%|▎         | 60/2220 [21:08<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.128]Steps:   3%|▎         | 60/2220 [21:10<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.24] Steps:   3%|▎         | 60/2220 [21:12<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.0798]Steps:   3%|▎         | 60/2220 [21:14<9:27:46, 15.77s/it, lr=0.0001, step_loss=0.223] Steps:   3%|▎         | 61/2220 [21:16<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.223]Steps:   3%|▎         | 61/2220 [21:16<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.161]Steps:   3%|▎         | 61/2220 [21:18<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.378]Steps:   3%|▎         | 61/2220 [21:20<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.209]Steps:   3%|▎         | 61/2220 [21:22<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.108]Steps:   3%|▎         | 61/2220 [21:24<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.154]Steps:   3%|▎         | 61/2220 [21:26<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.247]Steps:   3%|▎         | 61/2220 [21:27<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.49] Steps:   3%|▎         | 61/2220 [21:29<25:53:32, 43.17s/it, lr=0.0001, step_loss=0.17]Steps:   3%|▎         | 62/2220 [21:32<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.17]Steps:   3%|▎         | 62/2220 [21:32<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.167]Steps:   3%|▎         | 62/2220 [21:34<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.206]Steps:   3%|▎         | 62/2220 [21:36<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.0957]Steps:   3%|▎         | 62/2220 [21:37<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.344] Steps:   3%|▎         | 62/2220 [21:39<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.408]Steps:   3%|▎         | 62/2220 [21:41<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.254]Steps:   3%|▎         | 62/2220 [21:43<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.341]Steps:   3%|▎         | 62/2220 [21:45<20:56:42, 34.94s/it, lr=0.0001, step_loss=0.163]Steps:   3%|▎         | 63/2220 [21:47<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.163]Steps:   3%|▎         | 63/2220 [21:47<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.147]Steps:   3%|▎         | 63/2220 [21:49<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.184]Steps:   3%|▎         | 63/2220 [21:51<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.495]Steps:   3%|▎         | 63/2220 [21:53<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.176]Steps:   3%|▎         | 63/2220 [21:55<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.231]Steps:   3%|▎         | 63/2220 [21:57<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.0811]Steps:   3%|▎         | 63/2220 [21:59<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.311] Steps:   3%|▎         | 63/2220 [22:01<17:25:46, 29.09s/it, lr=0.0001, step_loss=0.295]Steps:   3%|▎         | 64/2220 [22:03<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.295]Steps:   3%|▎         | 64/2220 [22:03<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.0985]Steps:   3%|▎         | 64/2220 [22:05<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.198] Steps:   3%|▎         | 64/2220 [22:07<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.11] Steps:   3%|▎         | 64/2220 [22:09<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.201]Steps:   3%|▎         | 64/2220 [22:10<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.113]Steps:   3%|▎         | 64/2220 [22:12<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.094]Steps:   3%|▎         | 64/2220 [22:14<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.308]Steps:   3%|▎         | 64/2220 [22:16<14:58:17, 25.00s/it, lr=0.0001, step_loss=0.0975]Steps:   3%|▎         | 65/2220 [22:19<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.0975]Steps:   3%|▎         | 65/2220 [22:19<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.11]  Steps:   3%|▎         | 65/2220 [22:21<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.246]Steps:   3%|▎         | 65/2220 [22:22<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.232]Steps:   3%|▎         | 65/2220 [22:24<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.183]Steps:   3%|▎         | 65/2220 [22:26<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.168]Steps:   3%|▎         | 65/2220 [22:28<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.168]Steps:   3%|▎         | 65/2220 [22:30<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.498]Steps:   3%|▎         | 65/2220 [22:32<13:18:20, 22.23s/it, lr=0.0001, step_loss=0.113]Steps:   3%|▎         | 66/2220 [22:34<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.113]Steps:   3%|▎         | 66/2220 [22:34<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.215]Steps:   3%|▎         | 66/2220 [22:36<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.218]Steps:   3%|▎         | 66/2220 [22:38<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.155]Steps:   3%|▎         | 66/2220 [22:40<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.214]Steps:   3%|▎         | 66/2220 [22:42<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.147]Steps:   3%|▎         | 66/2220 [22:44<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.5]  Steps:   3%|▎         | 66/2220 [22:46<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.172]Steps:   3%|▎         | 66/2220 [22:48<12:06:37, 20.24s/it, lr=0.0001, step_loss=0.0962]Steps:   3%|▎         | 67/2220 [22:50<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.0962]Steps:   3%|▎         | 67/2220 [22:50<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.316] Steps:   3%|▎         | 67/2220 [22:52<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.0949]Steps:   3%|▎         | 67/2220 [22:54<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.248] Steps:   3%|▎         | 67/2220 [22:56<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.0976]Steps:   3%|▎         | 67/2220 [22:58<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.109] Steps:   3%|▎         | 67/2220 [23:00<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.221]Steps:   3%|▎         | 67/2220 [23:02<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.103]Steps:   3%|▎         | 67/2220 [23:04<11:20:08, 18.95s/it, lr=0.0001, step_loss=0.0885]Steps:   3%|▎         | 68/2220 [23:06<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.0885]Steps:   3%|▎         | 68/2220 [23:06<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.162] Steps:   3%|▎         | 68/2220 [23:08<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.159]Steps:   3%|▎         | 68/2220 [23:10<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.132]Steps:   3%|▎         | 68/2220 [23:11<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.147]Steps:   3%|▎         | 68/2220 [23:13<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.505]Steps:   3%|▎         | 68/2220 [23:15<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.152]Steps:   3%|▎         | 68/2220 [23:17<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.0904]Steps:   3%|▎         | 68/2220 [23:19<10:44:38, 17.97s/it, lr=0.0001, step_loss=0.459] Steps:   3%|▎         | 69/2220 [23:21<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.459]Steps:   3%|▎         | 69/2220 [23:22<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.113]Steps:   3%|▎         | 69/2220 [23:23<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.367]Steps:   3%|▎         | 69/2220 [23:25<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.301]Steps:   3%|▎         | 69/2220 [23:27<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.303]Steps:   3%|▎         | 69/2220 [23:29<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.183]Steps:   3%|▎         | 69/2220 [23:31<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.134]Steps:   3%|▎         | 69/2220 [23:33<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.336]Steps:   3%|▎         | 69/2220 [23:35<10:20:10, 17.30s/it, lr=0.0001, step_loss=0.108]Steps:   3%|▎         | 70/2220 [23:37<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.108]Steps:   3%|▎         | 70/2220 [23:37<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.213]Steps:   3%|▎         | 70/2220 [23:39<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.126]Steps:   3%|▎         | 70/2220 [23:41<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.0465]Steps:   3%|▎         | 70/2220 [23:43<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.531] Steps:   3%|▎         | 70/2220 [23:45<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.131]Steps:   3%|▎         | 70/2220 [23:47<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.209]Steps:   3%|▎         | 70/2220 [23:49<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.257]Steps:   3%|▎         | 70/2220 [23:51<10:01:59, 16.80s/it, lr=0.0001, step_loss=0.159]Steps:   3%|▎         | 71/2220 [23:53<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.159] Steps:   3%|▎         | 71/2220 [23:53<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.0866]Steps:   3%|▎         | 71/2220 [23:55<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.16]  Steps:   3%|▎         | 71/2220 [23:57<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.135]Steps:   3%|▎         | 71/2220 [23:59<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.52] Steps:   3%|▎         | 71/2220 [24:01<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.0902]Steps:   3%|▎         | 71/2220 [24:03<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.105] Steps:   3%|▎         | 71/2220 [24:04<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.402]Steps:   3%|▎         | 71/2220 [24:06<9:52:33, 16.54s/it, lr=0.0001, step_loss=0.136]Steps:   3%|▎         | 72/2220 [24:08<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.136]Steps:   3%|▎         | 72/2220 [24:08<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.198]Steps:   3%|▎         | 72/2220 [24:10<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.309]Steps:   3%|▎         | 72/2220 [24:11<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.186]Steps:   3%|▎         | 72/2220 [24:13<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.167]Steps:   3%|▎         | 72/2220 [24:14<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.174]Steps:   3%|▎         | 72/2220 [24:16<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.133]Steps:   3%|▎         | 72/2220 [24:17<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.317]Steps:   3%|▎         | 72/2220 [24:19<9:34:16, 16.04s/it, lr=0.0001, step_loss=0.212]Steps:   3%|▎         | 73/2220 [24:21<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.212]Steps:   3%|▎         | 73/2220 [24:21<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.287]Steps:   3%|▎         | 73/2220 [24:22<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.194]Steps:   3%|▎         | 73/2220 [24:24<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.18] Steps:   3%|▎         | 73/2220 [24:25<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.0616]Steps:   3%|▎         | 73/2220 [24:27<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.167] Steps:   3%|▎         | 73/2220 [24:28<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.0984]Steps:   3%|▎         | 73/2220 [24:30<8:58:04, 15.04s/it, lr=0.0001, step_loss=0.135] Steps:   3%|▎         | 74/2220 [24:32<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.135]Steps:   3%|▎         | 74/2220 [24:32<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.132]Steps:   3%|▎         | 74/2220 [24:52<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.162]Steps:   3%|▎         | 74/2220 [24:56<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.316]Steps:   3%|▎         | 74/2220 [24:59<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.382]Steps:   3%|▎         | 74/2220 [25:02<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.132]Steps:   3%|▎         | 74/2220 [25:05<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.173]Steps:   3%|▎         | 74/2220 [25:08<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.517]Steps:   3%|▎         | 74/2220 [25:10<8:21:27, 14.02s/it, lr=0.0001, step_loss=0.317]Steps:   3%|▎         | 75/2220 [25:13<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.317]Steps:   3%|▎         | 75/2220 [25:13<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.261]Steps:   3%|▎         | 75/2220 [25:15<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.188]Steps:   3%|▎         | 75/2220 [25:16<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.166]Steps:   3%|▎         | 75/2220 [25:18<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.329]Steps:   3%|▎         | 75/2220 [25:20<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.102]Steps:   3%|▎         | 75/2220 [25:22<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.261]Steps:   3%|▎         | 75/2220 [25:24<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.093]Steps:   3%|▎         | 75/2220 [25:26<13:04:45, 21.95s/it, lr=0.0001, step_loss=0.17] Steps:   3%|▎         | 76/2220 [25:28<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.17]Steps:   3%|▎         | 76/2220 [25:28<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.101]Steps:   3%|▎         | 76/2220 [25:30<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.121]Steps:   3%|▎         | 76/2220 [25:32<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.389]Steps:   3%|▎         | 76/2220 [25:34<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.156]Steps:   3%|▎         | 76/2220 [25:36<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.177]Steps:   3%|▎         | 76/2220 [25:38<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.108]Steps:   3%|▎         | 76/2220 [25:40<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.354]Steps:   3%|▎         | 76/2220 [25:42<11:55:42, 20.03s/it, lr=0.0001, step_loss=0.171]Steps:   3%|▎         | 77/2220 [25:44<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.171]Steps:   3%|▎         | 77/2220 [25:44<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.0561]Steps:   3%|▎         | 77/2220 [25:46<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.14]  Steps:   3%|▎         | 77/2220 [25:48<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.179]Steps:   3%|▎         | 77/2220 [25:50<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.574]Steps:   3%|▎         | 77/2220 [25:51<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.185]Steps:   3%|▎         | 77/2220 [25:53<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.105]Steps:   3%|▎         | 77/2220 [25:55<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.197]Steps:   3%|▎         | 77/2220 [25:57<11:07:55, 18.70s/it, lr=0.0001, step_loss=0.0513]Steps:   4%|▎         | 78/2220 [26:00<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.0513]Steps:   4%|▎         | 78/2220 [26:00<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.509] Steps:   4%|▎         | 78/2220 [26:02<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.116]Steps:   4%|▎         | 78/2220 [26:04<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.278]Steps:   4%|▎         | 78/2220 [26:05<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.136]Steps:   4%|▎         | 78/2220 [26:07<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.178]Steps:   4%|▎         | 78/2220 [26:09<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.124]Steps:   4%|▎         | 78/2220 [26:11<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.258]Steps:   4%|▎         | 78/2220 [26:13<10:40:50, 17.95s/it, lr=0.0001, step_loss=0.111]Steps:   4%|▎         | 79/2220 [26:15<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.111]Steps:   4%|▎         | 79/2220 [26:15<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.527]Steps:   4%|▎         | 79/2220 [26:17<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.0836]Steps:   4%|▎         | 79/2220 [26:19<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.476] Steps:   4%|▎         | 79/2220 [26:21<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.133]Steps:   4%|▎         | 79/2220 [26:23<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.416]Steps:   4%|▎         | 79/2220 [26:25<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.216]Steps:   4%|▎         | 79/2220 [26:27<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.121]Steps:   4%|▎         | 79/2220 [26:29<10:11:43, 17.14s/it, lr=0.0001, step_loss=0.0957]Steps:   4%|▎         | 80/2220 [26:31<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.0957] 11/28/2024 23:35:13 - INFO - __main__ - Step 80: Test Loss = 0.1944
Steps:   4%|▎         | 80/2220 [28:01<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.0864]Steps:   4%|▎         | 80/2220 [28:04<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.0975]Steps:   4%|▎         | 80/2220 [28:06<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.213] Steps:   4%|▎         | 80/2220 [28:08<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.258]Steps:   4%|▎         | 80/2220 [28:10<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.145]Steps:   4%|▎         | 80/2220 [28:12<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.271]Steps:   4%|▎         | 80/2220 [28:13<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.106]Steps:   4%|▎         | 80/2220 [28:15<9:57:20, 16.75s/it, lr=0.0001, step_loss=0.142]Steps:   4%|▎         | 81/2220 [28:18<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.142]Steps:   4%|▎         | 81/2220 [28:18<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.0965]Steps:   4%|▎         | 81/2220 [28:19<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.319] Steps:   4%|▎         | 81/2220 [28:21<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.0994]Steps:   4%|▎         | 81/2220 [28:23<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.223] Steps:   4%|▎         | 81/2220 [28:25<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.109]Steps:   4%|▎         | 81/2220 [28:27<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.159]Steps:   4%|▎         | 81/2220 [28:29<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.257]Steps:   4%|▎         | 81/2220 [28:31<25:55:35, 43.64s/it, lr=0.0001, step_loss=0.182]Steps:   4%|▎         | 82/2220 [28:33<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.182]Steps:   4%|▎         | 82/2220 [28:33<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.261]Steps:   4%|▎         | 82/2220 [28:35<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.541]Steps:   4%|▎         | 82/2220 [28:37<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.523]Steps:   4%|▎         | 82/2220 [28:39<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.276]Steps:   4%|▎         | 82/2220 [28:41<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.0997]Steps:   4%|▎         | 82/2220 [28:43<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.072] Steps:   4%|▎         | 82/2220 [28:45<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.141]Steps:   4%|▎         | 82/2220 [28:46<20:54:21, 35.20s/it, lr=0.0001, step_loss=0.185]Steps:   4%|▎         | 83/2220 [28:49<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.185]Steps:   4%|▎         | 83/2220 [28:49<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.218]Steps:   4%|▎         | 83/2220 [28:51<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.17] Steps:   4%|▎         | 83/2220 [28:52<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.185]Steps:   4%|▎         | 83/2220 [28:54<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.359]Steps:   4%|▎         | 83/2220 [28:56<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.0938]Steps:   4%|▎         | 83/2220 [28:58<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.151] Steps:   4%|▎         | 83/2220 [29:00<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.306]Steps:   4%|▎         | 83/2220 [29:02<17:24:24, 29.32s/it, lr=0.0001, step_loss=0.176]Steps:   4%|▍         | 84/2220 [29:04<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.176]Steps:   4%|▍         | 84/2220 [29:04<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.112]Steps:   4%|▍         | 84/2220 [29:06<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.0708]Steps:   4%|▍         | 84/2220 [29:08<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.204] Steps:   4%|▍         | 84/2220 [29:10<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.573]Steps:   4%|▍         | 84/2220 [29:12<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.356]Steps:   4%|▍         | 84/2220 [29:14<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.0769]Steps:   4%|▍         | 84/2220 [29:16<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.103] Steps:   4%|▍         | 84/2220 [29:18<14:57:54, 25.22s/it, lr=0.0001, step_loss=0.149]Steps:   4%|▍         | 85/2220 [29:20<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.149]Steps:   4%|▍         | 85/2220 [29:20<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.356]Steps:   4%|▍         | 85/2220 [29:22<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.129]Steps:   4%|▍         | 85/2220 [29:24<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.181]Steps:   4%|▍         | 85/2220 [29:26<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.486]Steps:   4%|▍         | 85/2220 [29:28<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.15] Steps:   4%|▍         | 85/2220 [29:29<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.536]Steps:   4%|▍         | 85/2220 [29:31<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.0906]Steps:   4%|▍         | 85/2220 [29:34<13:17:11, 22.40s/it, lr=0.0001, step_loss=0.518] Steps:   4%|▍         | 86/2220 [29:36<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.518]Steps:   4%|▍         | 86/2220 [29:36<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.119]Steps:   4%|▍         | 86/2220 [29:38<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.0776]Steps:   4%|▍         | 86/2220 [29:40<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.139] Steps:   4%|▍         | 86/2220 [29:42<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.173]Steps:   4%|▍         | 86/2220 [29:44<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.293]Steps:   4%|▍         | 86/2220 [29:46<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.193]Steps:   4%|▍         | 86/2220 [29:48<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.21] Steps:   4%|▍         | 86/2220 [29:50<12:07:14, 20.45s/it, lr=0.0001, step_loss=0.122]Steps:   4%|▍         | 87/2220 [29:52<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.122]Steps:   4%|▍         | 87/2220 [29:52<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.214]Steps:   4%|▍         | 87/2220 [29:54<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.183]Steps:   4%|▍         | 87/2220 [29:56<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.29] Steps:   4%|▍         | 87/2220 [29:57<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.369]Steps:   4%|▍         | 87/2220 [29:59<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.282]Steps:   4%|▍         | 87/2220 [30:01<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.182]Steps:   4%|▍         | 87/2220 [30:03<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.263]Steps:   4%|▍         | 87/2220 [30:05<11:16:22, 19.03s/it, lr=0.0001, step_loss=0.0819]Steps:   4%|▍         | 88/2220 [30:07<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.0819]Steps:   4%|▍         | 88/2220 [30:07<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.206] Steps:   4%|▍         | 88/2220 [30:09<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.142]Steps:   4%|▍         | 88/2220 [30:11<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.511]Steps:   4%|▍         | 88/2220 [30:13<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.181]Steps:   4%|▍         | 88/2220 [30:15<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.301]Steps:   4%|▍         | 88/2220 [30:17<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.0964]Steps:   4%|▍         | 88/2220 [30:19<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.127] Steps:   4%|▍         | 88/2220 [30:20<10:38:01, 17.96s/it, lr=0.0001, step_loss=0.196]Steps:   4%|▍         | 89/2220 [30:23<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.196]Steps:   4%|▍         | 89/2220 [30:23<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.167]Steps:   4%|▍         | 89/2220 [30:24<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.0892]Steps:   4%|▍         | 89/2220 [30:26<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.243] Steps:   4%|▍         | 89/2220 [30:28<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.167]Steps:   4%|▍         | 89/2220 [30:30<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.223]Steps:   4%|▍         | 89/2220 [30:32<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.111]Steps:   4%|▍         | 89/2220 [30:34<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.582]Steps:   4%|▍         | 89/2220 [30:36<10:09:52, 17.17s/it, lr=0.0001, step_loss=0.189]Steps:   4%|▍         | 90/2220 [30:38<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.189] Steps:   4%|▍         | 90/2220 [30:38<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.0676]Steps:   4%|▍         | 90/2220 [30:40<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.0986]Steps:   4%|▍         | 90/2220 [30:42<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.0791]Steps:   4%|▍         | 90/2220 [30:44<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.157] Steps:   4%|▍         | 90/2220 [30:46<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.191]Steps:   4%|▍         | 90/2220 [30:48<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.138]Steps:   4%|▍         | 90/2220 [30:50<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.0925]Steps:   4%|▍         | 90/2220 [30:51<9:54:12, 16.74s/it, lr=0.0001, step_loss=0.183] Steps:   4%|▍         | 91/2220 [30:54<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.183]Steps:   4%|▍         | 91/2220 [30:54<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.101]Steps:   4%|▍         | 91/2220 [30:56<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.192]Steps:   4%|▍         | 91/2220 [30:58<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.226]Steps:   4%|▍         | 91/2220 [31:00<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.138]Steps:   4%|▍         | 91/2220 [31:02<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.237]Steps:   4%|▍         | 91/2220 [31:04<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.18] Steps:   4%|▍         | 91/2220 [31:05<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.207]Steps:   4%|▍         | 91/2220 [31:07<9:39:24, 16.33s/it, lr=0.0001, step_loss=0.107]Steps:   4%|▍         | 92/2220 [31:10<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.107]Steps:   4%|▍         | 92/2220 [31:10<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.13] Steps:   4%|▍         | 92/2220 [31:12<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.175]Steps:   4%|▍         | 92/2220 [31:14<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.146]Steps:   4%|▍         | 92/2220 [31:16<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.101]Steps:   4%|▍         | 92/2220 [31:17<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.18] Steps:   4%|▍         | 92/2220 [31:19<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.317]Steps:   4%|▍         | 92/2220 [31:21<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.357]Steps:   4%|▍         | 92/2220 [31:23<9:37:18, 16.28s/it, lr=0.0001, step_loss=0.114]Steps:   4%|▍         | 93/2220 [31:26<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.114]Steps:   4%|▍         | 93/2220 [31:26<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.13] Steps:   4%|▍         | 93/2220 [31:28<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.118]Steps:   4%|▍         | 93/2220 [31:29<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.086]Steps:   4%|▍         | 93/2220 [31:31<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.0813]Steps:   4%|▍         | 93/2220 [31:33<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.203] Steps:   4%|▍         | 93/2220 [31:35<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.0863]Steps:   4%|▍         | 93/2220 [31:37<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.175] Steps:   4%|▍         | 93/2220 [31:39<9:33:44, 16.18s/it, lr=0.0001, step_loss=0.228]Steps:   4%|▍         | 94/2220 [31:41<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.228]Steps:   4%|▍         | 94/2220 [31:41<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.0842]Steps:   4%|▍         | 94/2220 [31:43<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.313] Steps:   4%|▍         | 94/2220 [31:45<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.301]Steps:   4%|▍         | 94/2220 [31:47<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.206]Steps:   4%|▍         | 94/2220 [31:49<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.101]Steps:   4%|▍         | 94/2220 [31:51<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.184]Steps:   4%|▍         | 94/2220 [31:53<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.118]Steps:   4%|▍         | 94/2220 [31:55<9:26:48, 16.00s/it, lr=0.0001, step_loss=0.203]Steps:   4%|▍         | 95/2220 [31:57<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.203]Steps:   4%|▍         | 95/2220 [31:57<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.173]Steps:   4%|▍         | 95/2220 [31:59<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.36] Steps:   4%|▍         | 95/2220 [32:01<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.276]Steps:   4%|▍         | 95/2220 [32:02<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.146]Steps:   4%|▍         | 95/2220 [32:04<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.548]Steps:   4%|▍         | 95/2220 [32:06<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.315]Steps:   4%|▍         | 95/2220 [32:08<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.184]Steps:   4%|▍         | 95/2220 [32:10<9:21:53, 15.87s/it, lr=0.0001, step_loss=0.306]Steps:   4%|▍         | 96/2220 [32:12<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.306]Steps:   4%|▍         | 96/2220 [32:13<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.159]Steps:   4%|▍         | 96/2220 [32:14<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.0819]Steps:   4%|▍         | 96/2220 [32:16<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.292] Steps:   4%|▍         | 96/2220 [32:18<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.168]Steps:   4%|▍         | 96/2220 [32:20<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.0878]Steps:   4%|▍         | 96/2220 [32:22<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.126] Steps:   4%|▍         | 96/2220 [32:24<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.0678]Steps:   4%|▍         | 96/2220 [32:26<9:18:40, 15.78s/it, lr=0.0001, step_loss=0.259] Steps:   4%|▍         | 97/2220 [32:28<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.259]Steps:   4%|▍         | 97/2220 [32:28<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.202]Steps:   4%|▍         | 97/2220 [32:30<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.0665]Steps:   4%|▍         | 97/2220 [32:32<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.103] Steps:   4%|▍         | 97/2220 [32:34<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.138]Steps:   4%|▍         | 97/2220 [32:36<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.178]Steps:   4%|▍         | 97/2220 [32:38<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.0946]Steps:   4%|▍         | 97/2220 [32:40<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.54]  Steps:   4%|▍         | 97/2220 [32:42<9:15:14, 15.69s/it, lr=0.0001, step_loss=0.215]Steps:   4%|▍         | 98/2220 [32:44<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.215]Steps:   4%|▍         | 98/2220 [32:44<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.112]Steps:   4%|▍         | 98/2220 [32:46<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.136]Steps:   4%|▍         | 98/2220 [32:48<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.275]Steps:   4%|▍         | 98/2220 [32:50<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.0749]Steps:   4%|▍         | 98/2220 [32:52<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.177] Steps:   4%|▍         | 98/2220 [32:54<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.134]Steps:   4%|▍         | 98/2220 [32:56<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.123]Steps:   4%|▍         | 98/2220 [32:58<9:16:54, 15.75s/it, lr=0.0001, step_loss=0.232]Steps:   4%|▍         | 99/2220 [33:00<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.232]Steps:   4%|▍         | 99/2220 [33:00<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.434]Steps:   4%|▍         | 99/2220 [33:02<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.168]Steps:   4%|▍         | 99/2220 [33:03<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.121]Steps:   4%|▍         | 99/2220 [33:05<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.116]Steps:   4%|▍         | 99/2220 [33:07<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.33] Steps:   4%|▍         | 99/2220 [33:09<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.329]Steps:   4%|▍         | 99/2220 [33:11<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.271]Steps:   4%|▍         | 99/2220 [33:13<9:19:16, 15.82s/it, lr=0.0001, step_loss=0.294]Steps:   5%|▍         | 100/2220 [33:16<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.294]11/28/2024 23:41:59 - INFO - __main__ - Step 100: Test Loss = 0.1582
Steps:   5%|▍         | 100/2220 [34:47<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.318]Steps:   5%|▍         | 100/2220 [34:49<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.0824]Steps:   5%|▍         | 100/2220 [34:51<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.21]  Steps:   5%|▍         | 100/2220 [34:53<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.107]Steps:   5%|▍         | 100/2220 [34:54<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.12] Steps:   5%|▍         | 100/2220 [34:56<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.209]Steps:   5%|▍         | 100/2220 [34:58<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.516]Steps:   5%|▍         | 100/2220 [35:00<9:17:52, 15.79s/it, lr=0.0001, step_loss=0.21] Steps:   5%|▍         | 101/2220 [35:02<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.21]Steps:   5%|▍         | 101/2220 [35:02<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.327]Steps:   5%|▍         | 101/2220 [35:04<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.137]Steps:   5%|▍         | 101/2220 [35:06<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.213]Steps:   5%|▍         | 101/2220 [35:08<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.287]Steps:   5%|▍         | 101/2220 [35:10<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.0943]Steps:   5%|▍         | 101/2220 [35:12<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.377] Steps:   5%|▍         | 101/2220 [35:14<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.545]Steps:   5%|▍         | 101/2220 [35:16<25:22:09, 43.10s/it, lr=0.0001, step_loss=0.331]Steps:   5%|▍         | 102/2220 [35:18<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.331]Steps:   5%|▍         | 102/2220 [35:18<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.194]Steps:   5%|▍         | 102/2220 [35:20<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.511]Steps:   5%|▍         | 102/2220 [35:22<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.229]Steps:   5%|▍         | 102/2220 [35:24<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.105]Steps:   5%|▍         | 102/2220 [35:26<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.159]Steps:   5%|▍         | 102/2220 [35:27<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.0752]Steps:   5%|▍         | 102/2220 [35:29<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.41]  Steps:   5%|▍         | 102/2220 [35:31<20:29:02, 34.82s/it, lr=0.0001, step_loss=0.486]Steps:   5%|▍         | 103/2220 [35:34<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.486]Steps:   5%|▍         | 103/2220 [35:34<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.125]Steps:   5%|▍         | 103/2220 [35:35<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.177]Steps:   5%|▍         | 103/2220 [35:37<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.237]Steps:   5%|▍         | 103/2220 [35:39<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.0803]Steps:   5%|▍         | 103/2220 [35:41<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.257] Steps:   5%|▍         | 103/2220 [35:43<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.137]Steps:   5%|▍         | 103/2220 [35:45<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.233]Steps:   5%|▍         | 103/2220 [35:47<17:06:06, 29.08s/it, lr=0.0001, step_loss=0.0754]Steps:   5%|▍         | 104/2220 [35:49<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.0754]Steps:   5%|▍         | 104/2220 [35:49<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.135] Steps:   5%|▍         | 104/2220 [35:51<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.166]Steps:   5%|▍         | 104/2220 [35:53<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.518]Steps:   5%|▍         | 104/2220 [35:55<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.0725]Steps:   5%|▍         | 104/2220 [35:57<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.154] Steps:   5%|▍         | 104/2220 [35:59<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.13] Steps:   5%|▍         | 104/2220 [36:01<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.163]Steps:   5%|▍         | 104/2220 [36:03<14:44:30, 25.08s/it, lr=0.0001, step_loss=0.117]Steps:   5%|▍         | 105/2220 [36:05<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.117]Steps:   5%|▍         | 105/2220 [36:05<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.114]Steps:   5%|▍         | 105/2220 [36:07<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.319]Steps:   5%|▍         | 105/2220 [36:09<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.131]Steps:   5%|▍         | 105/2220 [36:11<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.114]Steps:   5%|▍         | 105/2220 [36:13<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.191]Steps:   5%|▍         | 105/2220 [36:15<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.201]Steps:   5%|▍         | 105/2220 [36:17<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.192]Steps:   5%|▍         | 105/2220 [36:19<13:06:01, 22.30s/it, lr=0.0001, step_loss=0.0797]Steps:   5%|▍         | 106/2220 [36:21<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.0797]Steps:   5%|▍         | 106/2220 [36:21<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.0936]Steps:   5%|▍         | 106/2220 [36:23<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.282] Steps:   5%|▍         | 106/2220 [36:25<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.393]Steps:   5%|▍         | 106/2220 [36:27<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.128]Steps:   5%|▍         | 106/2220 [36:29<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.123]Steps:   5%|▍         | 106/2220 [36:31<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.105]Steps:   5%|▍         | 106/2220 [36:33<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.066]Steps:   5%|▍         | 106/2220 [36:35<11:59:33, 20.42s/it, lr=0.0001, step_loss=0.174]Steps:   5%|▍         | 107/2220 [36:37<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.174]Steps:   5%|▍         | 107/2220 [36:37<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.535]Steps:   5%|▍         | 107/2220 [36:39<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.101]Steps:   5%|▍         | 107/2220 [36:41<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.32] Steps:   5%|▍         | 107/2220 [36:42<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.102]Steps:   5%|▍         | 107/2220 [36:44<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.173]Steps:   5%|▍         | 107/2220 [36:46<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.222]Steps:   5%|▍         | 107/2220 [36:48<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.232]Steps:   5%|▍         | 107/2220 [36:50<11:09:10, 19.00s/it, lr=0.0001, step_loss=0.134]Steps:   5%|▍         | 108/2220 [36:53<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.134]Steps:   5%|▍         | 108/2220 [36:53<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.165]Steps:   5%|▍         | 108/2220 [36:54<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.233]Steps:   5%|▍         | 108/2220 [36:56<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.139]Steps:   5%|▍         | 108/2220 [36:58<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.388]Steps:   5%|▍         | 108/2220 [37:00<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.168]Steps:   5%|▍         | 108/2220 [37:02<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.456]Steps:   5%|▍         | 108/2220 [37:04<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.163]Steps:   5%|▍         | 108/2220 [37:06<10:34:27, 18.02s/it, lr=0.0001, step_loss=0.13] Steps:   5%|▍         | 109/2220 [37:08<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.13]Steps:   5%|▍         | 109/2220 [37:08<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.163]Steps:   5%|▍         | 109/2220 [37:10<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.227]Steps:   5%|▍         | 109/2220 [37:12<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.1]  Steps:   5%|▍         | 109/2220 [37:14<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.381]Steps:   5%|▍         | 109/2220 [37:16<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.0787]Steps:   5%|▍         | 109/2220 [37:18<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.197] Steps:   5%|▍         | 109/2220 [37:19<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.274]Steps:   5%|▍         | 109/2220 [37:21<10:08:02, 17.28s/it, lr=0.0001, step_loss=0.35] Steps:   5%|▍         | 110/2220 [37:24<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.35] Steps:   5%|▍         | 110/2220 [37:24<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.36]Steps:   5%|▍         | 110/2220 [37:26<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.226]Steps:   5%|▍         | 110/2220 [37:27<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.148]Steps:   5%|▍         | 110/2220 [37:29<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.27] Steps:   5%|▍         | 110/2220 [37:32<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.142]Steps:   5%|▍         | 110/2220 [37:34<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.0689]Steps:   5%|▍         | 110/2220 [37:35<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.347] Steps:   5%|▍         | 110/2220 [37:37<9:49:17, 16.76s/it, lr=0.0001, step_loss=0.172]Steps:   5%|▌         | 111/2220 [37:40<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.172]Steps:   5%|▌         | 111/2220 [37:40<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.247]Steps:   5%|▌         | 111/2220 [37:41<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.159]Steps:   5%|▌         | 111/2220 [37:43<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.469]Steps:   5%|▌         | 111/2220 [37:46<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.231]Steps:   5%|▌         | 111/2220 [37:48<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.181]Steps:   5%|▌         | 111/2220 [37:49<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.262]Steps:   5%|▌         | 111/2220 [37:51<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.0662]Steps:   5%|▌         | 111/2220 [37:53<9:39:27, 16.49s/it, lr=0.0001, step_loss=0.177] Steps:   5%|▌         | 112/2220 [37:55<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.177]Steps:   5%|▌         | 112/2220 [37:56<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.12] Steps:   5%|▌         | 112/2220 [37:57<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.291]Steps:   5%|▌         | 112/2220 [37:59<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.224]Steps:   5%|▌         | 112/2220 [38:02<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.112]Steps:   5%|▌         | 112/2220 [38:03<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.0921]Steps:   5%|▌         | 112/2220 [38:05<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.504] Steps:   5%|▌         | 112/2220 [38:07<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.156]Steps:   5%|▌         | 112/2220 [38:09<9:33:30, 16.32s/it, lr=0.0001, step_loss=0.117]Steps:   5%|▌         | 113/2220 [38:11<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.117]Steps:   5%|▌         | 113/2220 [38:11<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.224]Steps:   5%|▌         | 113/2220 [38:13<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.153]Steps:   5%|▌         | 113/2220 [38:15<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.117]Steps:   5%|▌         | 113/2220 [38:17<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.185]Steps:   5%|▌         | 113/2220 [38:19<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.326]Steps:   5%|▌         | 113/2220 [38:21<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.18] Steps:   5%|▌         | 113/2220 [38:23<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.273]Steps:   5%|▌         | 113/2220 [38:25<9:26:22, 16.13s/it, lr=0.0001, step_loss=0.329]Steps:   5%|▌         | 114/2220 [38:27<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.329]Steps:   5%|▌         | 114/2220 [38:27<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.0887]Steps:   5%|▌         | 114/2220 [38:29<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.125] Steps:   5%|▌         | 114/2220 [38:31<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.0707]Steps:   5%|▌         | 114/2220 [38:32<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.114] Steps:   5%|▌         | 114/2220 [38:34<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.507]Steps:   5%|▌         | 114/2220 [38:36<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.102]Steps:   5%|▌         | 114/2220 [38:38<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.223]Steps:   5%|▌         | 114/2220 [38:40<9:20:41, 15.97s/it, lr=0.0001, step_loss=0.286]Steps:   5%|▌         | 115/2220 [38:43<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.286]Steps:   5%|▌         | 115/2220 [38:43<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.101]Steps:   5%|▌         | 115/2220 [38:44<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.478]Steps:   5%|▌         | 115/2220 [38:46<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.185]Steps:   5%|▌         | 115/2220 [38:48<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.194]Steps:   5%|▌         | 115/2220 [38:50<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.161]Steps:   5%|▌         | 115/2220 [38:52<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.437]Steps:   5%|▌         | 115/2220 [38:54<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.313]Steps:   5%|▌         | 115/2220 [38:56<9:18:43, 15.93s/it, lr=0.0001, step_loss=0.2]  Steps:   5%|▌         | 116/2220 [38:58<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.2]Steps:   5%|▌         | 116/2220 [38:58<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.134]Steps:   5%|▌         | 116/2220 [39:00<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.0876]Steps:   5%|▌         | 116/2220 [39:02<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.183] Steps:   5%|▌         | 116/2220 [39:04<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.248]Steps:   5%|▌         | 116/2220 [39:06<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.111]Steps:   5%|▌         | 116/2220 [39:08<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.149]Steps:   5%|▌         | 116/2220 [39:10<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.152]Steps:   5%|▌         | 116/2220 [39:12<9:13:34, 15.79s/it, lr=0.0001, step_loss=0.315]Steps:   5%|▌         | 117/2220 [39:14<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.315]Steps:   5%|▌         | 117/2220 [39:14<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.226]Steps:   5%|▌         | 117/2220 [39:16<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.212]Steps:   5%|▌         | 117/2220 [39:18<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.124]Steps:   5%|▌         | 117/2220 [39:19<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.109]Steps:   5%|▌         | 117/2220 [39:22<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.404]Steps:   5%|▌         | 117/2220 [39:24<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.137]Steps:   5%|▌         | 117/2220 [39:26<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.127]Steps:   5%|▌         | 117/2220 [39:27<9:13:35, 15.79s/it, lr=0.0001, step_loss=0.09] Steps:   5%|▌         | 118/2220 [39:29<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.09]Steps:   5%|▌         | 118/2220 [39:30<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.0734]Steps:   5%|▌         | 118/2220 [39:31<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.156] Steps:   5%|▌         | 118/2220 [39:33<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.151]Steps:   5%|▌         | 118/2220 [39:35<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.112]Steps:   5%|▌         | 118/2220 [39:37<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.113]Steps:   5%|▌         | 118/2220 [39:39<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.0896]Steps:   5%|▌         | 118/2220 [39:41<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.324] Steps:   5%|▌         | 118/2220 [39:43<9:11:36, 15.75s/it, lr=0.0001, step_loss=0.161]Steps:   5%|▌         | 119/2220 [39:45<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.161]Steps:   5%|▌         | 119/2220 [39:45<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.18] Steps:   5%|▌         | 119/2220 [39:47<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.339]Steps:   5%|▌         | 119/2220 [39:49<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.163]Steps:   5%|▌         | 119/2220 [39:51<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.153]Steps:   5%|▌         | 119/2220 [39:53<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.146]Steps:   5%|▌         | 119/2220 [39:55<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.184]Steps:   5%|▌         | 119/2220 [39:57<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.105]Steps:   5%|▌         | 119/2220 [39:59<9:10:24, 15.72s/it, lr=0.0001, step_loss=0.0607]Steps:   5%|▌         | 120/2220 [40:01<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.0607]11/28/2024 23:48:43 - INFO - __main__ - Step 120: Test Loss = 0.1770
Steps:   5%|▌         | 120/2220 [41:32<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.133] Steps:   5%|▌         | 120/2220 [41:34<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.148]Steps:   5%|▌         | 120/2220 [41:36<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.0807]Steps:   5%|▌         | 120/2220 [41:37<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.12]  Steps:   5%|▌         | 120/2220 [41:39<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.0926]Steps:   5%|▌         | 120/2220 [41:41<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.127] Steps:   5%|▌         | 120/2220 [41:43<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.334]Steps:   5%|▌         | 120/2220 [41:45<9:11:24, 15.75s/it, lr=0.0001, step_loss=0.0886]Steps:   5%|▌         | 121/2220 [41:47<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.0886]Steps:   5%|▌         | 121/2220 [41:47<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.204] Steps:   5%|▌         | 121/2220 [41:49<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.131]Steps:   5%|▌         | 121/2220 [41:51<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.146]Steps:   5%|▌         | 121/2220 [41:53<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.227]Steps:   5%|▌         | 121/2220 [41:55<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.101]Steps:   5%|▌         | 121/2220 [41:57<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.147]Steps:   5%|▌         | 121/2220 [41:58<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.158]Steps:   5%|▌         | 121/2220 [42:00<24:58:19, 42.83s/it, lr=0.0001, step_loss=0.369]Steps:   5%|▌         | 122/2220 [42:03<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.369]Steps:   5%|▌         | 122/2220 [42:03<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.151]Steps:   5%|▌         | 122/2220 [42:04<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.449]Steps:   5%|▌         | 122/2220 [42:06<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.128]Steps:   5%|▌         | 122/2220 [42:08<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.222]Steps:   5%|▌         | 122/2220 [42:10<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.276]Steps:   5%|▌         | 122/2220 [42:12<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.278]Steps:   5%|▌         | 122/2220 [42:14<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.132]Steps:   5%|▌         | 122/2220 [42:17<20:11:42, 34.65s/it, lr=0.0001, step_loss=0.26] Steps:   6%|▌         | 123/2220 [42:19<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.26]Steps:   6%|▌         | 123/2220 [42:19<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.0878]Steps:   6%|▌         | 123/2220 [42:21<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.142] Steps:   6%|▌         | 123/2220 [42:22<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.345]Steps:   6%|▌         | 123/2220 [42:24<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.192]Steps:   6%|▌         | 123/2220 [42:26<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.231]Steps:   6%|▌         | 123/2220 [42:28<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.0931]Steps:   6%|▌         | 123/2220 [42:30<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.203] Steps:   6%|▌         | 123/2220 [42:32<16:56:13, 29.08s/it, lr=0.0001, step_loss=0.192]Steps:   6%|▌         | 124/2220 [42:34<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.192]Steps:   6%|▌         | 124/2220 [42:34<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.185]Steps:   6%|▌         | 124/2220 [42:37<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.075]Steps:   6%|▌         | 124/2220 [42:38<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.124]Steps:   6%|▌         | 124/2220 [42:40<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.17] Steps:   6%|▌         | 124/2220 [42:42<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.157]Steps:   6%|▌         | 124/2220 [42:44<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.115]Steps:   6%|▌         | 124/2220 [42:46<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.251]Steps:   6%|▌         | 124/2220 [42:48<14:34:32, 25.03s/it, lr=0.0001, step_loss=0.354]Steps:   6%|▌         | 125/2220 [42:50<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.354]Steps:   6%|▌         | 125/2220 [42:50<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.128]Steps:   6%|▌         | 125/2220 [42:52<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.106]Steps:   6%|▌         | 125/2220 [42:54<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.138]Steps:   6%|▌         | 125/2220 [42:56<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.341]Steps:   6%|▌         | 125/2220 [42:58<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.271]Steps:   6%|▌         | 125/2220 [43:00<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.0978]Steps:   6%|▌         | 125/2220 [43:02<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.187] Steps:   6%|▌         | 125/2220 [43:04<12:59:05, 22.31s/it, lr=0.0001, step_loss=0.186]Steps:   6%|▌         | 126/2220 [43:06<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.186]Steps:   6%|▌         | 126/2220 [43:06<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.23] Steps:   6%|▌         | 126/2220 [43:08<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.249]Steps:   6%|▌         | 126/2220 [43:10<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.116]Steps:   6%|▌         | 126/2220 [43:12<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.197]Steps:   6%|▌         | 126/2220 [43:14<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.173]Steps:   6%|▌         | 126/2220 [43:16<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.152]Steps:   6%|▌         | 126/2220 [43:17<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.201]Steps:   6%|▌         | 126/2220 [43:20<11:52:53, 20.43s/it, lr=0.0001, step_loss=0.313]Steps:   6%|▌         | 127/2220 [43:22<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.313]Steps:   6%|▌         | 127/2220 [43:22<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.496]Steps:   6%|▌         | 127/2220 [43:24<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.458]Steps:   6%|▌         | 127/2220 [43:26<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.207]Steps:   6%|▌         | 127/2220 [43:27<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.235]Steps:   6%|▌         | 127/2220 [43:29<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.146]Steps:   6%|▌         | 127/2220 [43:31<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.205]Steps:   6%|▌         | 127/2220 [43:33<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.135]Steps:   6%|▌         | 127/2220 [43:35<11:03:13, 19.01s/it, lr=0.0001, step_loss=0.125]Steps:   6%|▌         | 128/2220 [43:37<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.125]Steps:   6%|▌         | 128/2220 [43:37<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.241]Steps:   6%|▌         | 128/2220 [43:39<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.302]Steps:   6%|▌         | 128/2220 [43:41<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.195]Steps:   6%|▌         | 128/2220 [43:43<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.422]Steps:   6%|▌         | 128/2220 [43:45<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.408]Steps:   6%|▌         | 128/2220 [43:47<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.144]Steps:   6%|▌         | 128/2220 [43:50<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.231]Steps:   6%|▌         | 128/2220 [43:51<10:25:02, 17.93s/it, lr=0.0001, step_loss=0.267]Steps:   6%|▌         | 129/2220 [43:53<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.267]Steps:   6%|▌         | 129/2220 [43:53<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.453]Steps:   6%|▌         | 129/2220 [43:55<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.0997]Steps:   6%|▌         | 129/2220 [43:57<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.25]  Steps:   6%|▌         | 129/2220 [43:59<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.17]Steps:   6%|▌         | 129/2220 [44:01<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.265]Steps:   6%|▌         | 129/2220 [44:03<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.136]Steps:   6%|▌         | 129/2220 [44:05<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.114]Steps:   6%|▌         | 129/2220 [44:07<10:05:50, 17.38s/it, lr=0.0001, step_loss=0.169]Steps:   6%|▌         | 130/2220 [44:09<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.169] Steps:   6%|▌         | 130/2220 [44:09<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.139]Steps:   6%|▌         | 130/2220 [44:11<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.165]Steps:   6%|▌         | 130/2220 [44:13<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.418]Steps:   6%|▌         | 130/2220 [44:15<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.133]Steps:   6%|▌         | 130/2220 [44:17<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.09] Steps:   6%|▌         | 130/2220 [44:19<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.117]Steps:   6%|▌         | 130/2220 [44:21<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.211]Steps:   6%|▌         | 130/2220 [44:23<9:47:06, 16.85s/it, lr=0.0001, step_loss=0.0853]Steps:   6%|▌         | 131/2220 [44:25<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.0853]Steps:   6%|▌         | 131/2220 [44:25<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.222] Steps:   6%|▌         | 131/2220 [44:27<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.087]Steps:   6%|▌         | 131/2220 [44:29<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.387]Steps:   6%|▌         | 131/2220 [44:31<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.107]Steps:   6%|▌         | 131/2220 [44:32<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.168]Steps:   6%|▌         | 131/2220 [44:34<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.127]Steps:   6%|▌         | 131/2220 [44:36<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.116]Steps:   6%|▌         | 131/2220 [44:38<9:35:59, 16.54s/it, lr=0.0001, step_loss=0.0821]Steps:   6%|▌         | 132/2220 [44:40<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.0821]Steps:   6%|▌         | 132/2220 [44:40<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.343] Steps:   6%|▌         | 132/2220 [44:42<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.158]Steps:   6%|▌         | 132/2220 [44:44<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.278]Steps:   6%|▌         | 132/2220 [44:46<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.161]Steps:   6%|▌         | 132/2220 [44:48<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.206]Steps:   6%|▌         | 132/2220 [44:50<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.173]Steps:   6%|▌         | 132/2220 [44:52<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.0995]Steps:   6%|▌         | 132/2220 [44:54<9:24:26, 16.22s/it, lr=0.0001, step_loss=0.169] Steps:   6%|▌         | 133/2220 [44:56<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.169]Steps:   6%|▌         | 133/2220 [44:56<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.131]Steps:   6%|▌         | 133/2220 [44:58<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.205]Steps:   6%|▌         | 133/2220 [44:59<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.264]Steps:   6%|▌         | 133/2220 [45:02<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.0717]Steps:   6%|▌         | 133/2220 [45:03<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.348] Steps:   6%|▌         | 133/2220 [45:05<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.125]Steps:   6%|▌         | 133/2220 [45:07<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.0636]Steps:   6%|▌         | 133/2220 [45:09<9:16:04, 15.99s/it, lr=0.0001, step_loss=0.16]  Steps:   6%|▌         | 134/2220 [45:11<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.16]Steps:   6%|▌         | 134/2220 [45:12<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.144]Steps:   6%|▌         | 134/2220 [45:13<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.114]Steps:   6%|▌         | 134/2220 [45:15<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.326]Steps:   6%|▌         | 134/2220 [45:17<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.153]Steps:   6%|▌         | 134/2220 [45:19<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.151]Steps:   6%|▌         | 134/2220 [45:21<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.336]Steps:   6%|▌         | 134/2220 [45:23<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.514]Steps:   6%|▌         | 134/2220 [45:25<9:12:33, 15.89s/it, lr=0.0001, step_loss=0.444]Steps:   6%|▌         | 135/2220 [45:27<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.444]Steps:   6%|▌         | 135/2220 [45:27<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.161]Steps:   6%|▌         | 135/2220 [45:29<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.293]Steps:   6%|▌         | 135/2220 [45:31<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.144]Steps:   6%|▌         | 135/2220 [45:33<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.311]Steps:   6%|▌         | 135/2220 [45:35<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.122]Steps:   6%|▌         | 135/2220 [45:37<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.567]Steps:   6%|▌         | 135/2220 [45:39<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.427]Steps:   6%|▌         | 135/2220 [45:41<9:08:39, 15.79s/it, lr=0.0001, step_loss=0.312]Steps:   6%|▌         | 136/2220 [45:43<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.312]Steps:   6%|▌         | 136/2220 [45:43<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.174]Steps:   6%|▌         | 136/2220 [45:45<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.233]Steps:   6%|▌         | 136/2220 [45:47<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.461]Steps:   6%|▌         | 136/2220 [45:48<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.152]Steps:   6%|▌         | 136/2220 [45:50<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.152]Steps:   6%|▌         | 136/2220 [45:52<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.0763]Steps:   6%|▌         | 136/2220 [45:54<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.0796]Steps:   6%|▌         | 136/2220 [45:56<9:09:10, 15.81s/it, lr=0.0001, step_loss=0.528] Steps:   6%|▌         | 137/2220 [45:59<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.528]Steps:   6%|▌         | 137/2220 [45:59<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.174]Steps:   6%|▌         | 137/2220 [46:01<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.0917]Steps:   6%|▌         | 137/2220 [46:03<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.137] Steps:   6%|▌         | 137/2220 [46:05<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.178]Steps:   6%|▌         | 137/2220 [46:06<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.0964]Steps:   6%|▌         | 137/2220 [46:08<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.084] Steps:   6%|▌         | 137/2220 [46:10<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.119]Steps:   6%|▌         | 137/2220 [46:12<9:12:21, 15.91s/it, lr=0.0001, step_loss=0.151]Steps:   6%|▌         | 138/2220 [46:15<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.151]Steps:   6%|▌         | 138/2220 [46:15<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.123]Steps:   6%|▌         | 138/2220 [46:16<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.181]Steps:   6%|▌         | 138/2220 [46:18<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.259]Steps:   6%|▌         | 138/2220 [46:20<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.11] Steps:   6%|▌         | 138/2220 [46:22<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.346]Steps:   6%|▌         | 138/2220 [46:24<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.306]Steps:   6%|▌         | 138/2220 [46:26<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.158]Steps:   6%|▌         | 138/2220 [46:28<9:08:12, 15.80s/it, lr=0.0001, step_loss=0.171]Steps:   6%|▋         | 139/2220 [46:30<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.171]Steps:   6%|▋         | 139/2220 [46:30<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.167]Steps:   6%|▋         | 139/2220 [46:32<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.217]Steps:   6%|▋         | 139/2220 [46:34<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.174]Steps:   6%|▋         | 139/2220 [46:36<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.174]Steps:   6%|▋         | 139/2220 [46:38<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.311]Steps:   6%|▋         | 139/2220 [46:40<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.0915]Steps:   6%|▋         | 139/2220 [46:42<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.135] Steps:   6%|▋         | 139/2220 [46:43<9:04:12, 15.69s/it, lr=0.0001, step_loss=0.123]Steps:   6%|▋         | 140/2220 [46:46<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.123]11/28/2024 23:55:27 - INFO - __main__ - Step 140: Test Loss = 0.1720
Steps:   6%|▋         | 140/2220 [48:16<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.163]Steps:   6%|▋         | 140/2220 [48:19<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.139]Steps:   6%|▋         | 140/2220 [48:20<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.0907]Steps:   6%|▋         | 140/2220 [48:22<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.198] Steps:   6%|▋         | 140/2220 [48:24<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.114]Steps:   6%|▋         | 140/2220 [48:26<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.128]Steps:   6%|▋         | 140/2220 [48:28<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.195]Steps:   6%|▋         | 140/2220 [48:30<9:08:49, 15.83s/it, lr=0.0001, step_loss=0.0824]Steps:   6%|▋         | 141/2220 [48:32<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.0824]Steps:   6%|▋         | 141/2220 [48:32<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.0671]Steps:   6%|▋         | 141/2220 [48:34<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.156] Steps:   6%|▋         | 141/2220 [48:36<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.163]Steps:   6%|▋         | 141/2220 [48:38<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.152]Steps:   6%|▋         | 141/2220 [48:40<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.134]Steps:   6%|▋         | 141/2220 [48:42<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.211]Steps:   6%|▋         | 141/2220 [48:44<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.216]Steps:   6%|▋         | 141/2220 [48:45<24:42:37, 42.79s/it, lr=0.0001, step_loss=0.15] Steps:   6%|▋         | 142/2220 [48:48<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.15]Steps:   6%|▋         | 142/2220 [48:48<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.168]Steps:   6%|▋         | 142/2220 [48:50<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.129]Steps:   6%|▋         | 142/2220 [48:52<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.157]Steps:   6%|▋         | 142/2220 [48:53<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.0809]Steps:   6%|▋         | 142/2220 [48:55<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.313] Steps:   6%|▋         | 142/2220 [48:57<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.221]Steps:   6%|▋         | 142/2220 [48:59<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.368]Steps:   6%|▋         | 142/2220 [49:01<20:01:26, 34.69s/it, lr=0.0001, step_loss=0.106]Steps:   6%|▋         | 143/2220 [49:04<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.106]Steps:   6%|▋         | 143/2220 [49:04<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.382]Steps:   6%|▋         | 143/2220 [49:06<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.218]Steps:   6%|▋         | 143/2220 [49:08<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.135]Steps:   6%|▋         | 143/2220 [49:09<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.146]Steps:   6%|▋         | 143/2220 [49:11<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.168]Steps:   6%|▋         | 143/2220 [49:13<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.273]Steps:   6%|▋         | 143/2220 [49:15<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.0863]Steps:   6%|▋         | 143/2220 [49:17<16:50:20, 29.19s/it, lr=0.0001, step_loss=0.252] Steps:   6%|▋         | 144/2220 [49:19<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.252]Steps:   6%|▋         | 144/2220 [49:19<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.123]Steps:   6%|▋         | 144/2220 [49:21<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.123]Steps:   6%|▋         | 144/2220 [49:23<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.304]Steps:   6%|▋         | 144/2220 [49:25<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.463]Steps:   6%|▋         | 144/2220 [49:27<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.115]Steps:   6%|▋         | 144/2220 [49:29<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.197]Steps:   6%|▋         | 144/2220 [49:31<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.114]Steps:   6%|▋         | 144/2220 [49:33<14:27:54, 25.08s/it, lr=0.0001, step_loss=0.0901]Steps:   7%|▋         | 145/2220 [49:35<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.0901]Steps:   7%|▋         | 145/2220 [49:35<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.109] Steps:   7%|▋         | 145/2220 [49:37<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.513]Steps:   7%|▋         | 145/2220 [49:39<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.168]Steps:   7%|▋         | 145/2220 [49:41<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.08] Steps:   7%|▋         | 145/2220 [49:43<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.144]Steps:   7%|▋         | 145/2220 [49:44<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.134]Steps:   7%|▋         | 145/2220 [49:46<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.217]Steps:   7%|▋         | 145/2220 [49:48<12:48:22, 22.22s/it, lr=0.0001, step_loss=0.164]Steps:   7%|▋         | 146/2220 [49:50<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.164]Steps:   7%|▋         | 146/2220 [49:50<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.249]Steps:   7%|▋         | 146/2220 [49:52<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.258]Steps:   7%|▋         | 146/2220 [49:53<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.228]Steps:   7%|▋         | 146/2220 [49:55<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.103]Steps:   7%|▋         | 146/2220 [49:56<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.13] Steps:   7%|▋         | 146/2220 [49:58<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.136]Steps:   7%|▋         | 146/2220 [49:59<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.158]Steps:   7%|▋         | 146/2220 [50:01<11:33:35, 20.07s/it, lr=0.0001, step_loss=0.415]Steps:   7%|▋         | 147/2220 [50:03<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.415]Steps:   7%|▋         | 147/2220 [50:03<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.129]Steps:   7%|▋         | 147/2220 [50:04<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.273]Steps:   7%|▋         | 147/2220 [50:06<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.0724]Steps:   7%|▋         | 147/2220 [50:07<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.147] Steps:   7%|▋         | 147/2220 [50:09<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.0737]Steps:   7%|▋         | 147/2220 [50:11<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.124] Steps:   7%|▋         | 147/2220 [50:12<10:16:40, 17.85s/it, lr=0.0001, step_loss=0.112]Steps:   7%|▋         | 148/2220 [50:14<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.112] Steps:   7%|▋         | 148/2220 [50:15<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.0627]Steps:   7%|▋         | 148/2220 [50:34<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.119] Steps:   7%|▋         | 148/2220 [50:38<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.361]Steps:   7%|▋         | 148/2220 [50:42<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.127]Steps:   7%|▋         | 148/2220 [50:45<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.191]Steps:   7%|▋         | 148/2220 [50:48<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.256]Steps:   7%|▋         | 148/2220 [50:51<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.103]Steps:   7%|▋         | 148/2220 [50:53<9:13:11, 16.02s/it, lr=0.0001, step_loss=0.311]Steps:   7%|▋         | 149/2220 [50:55<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.311]Steps:   7%|▋         | 149/2220 [50:55<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.449]Steps:   7%|▋         | 149/2220 [50:57<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.529]Steps:   7%|▋         | 149/2220 [50:59<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.21] Steps:   7%|▋         | 149/2220 [51:01<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.285]Steps:   7%|▋         | 149/2220 [51:03<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.0855]Steps:   7%|▋         | 149/2220 [51:05<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.16]  Steps:   7%|▋         | 149/2220 [51:07<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.0778]Steps:   7%|▋         | 149/2220 [51:09<13:28:18, 23.42s/it, lr=0.0001, step_loss=0.168] Steps:   7%|▋         | 150/2220 [51:11<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.168]Steps:   7%|▋         | 150/2220 [51:11<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.183]Steps:   7%|▋         | 150/2220 [51:13<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.115]Steps:   7%|▋         | 150/2220 [51:15<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.321]Steps:   7%|▋         | 150/2220 [51:16<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.234]Steps:   7%|▋         | 150/2220 [51:18<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.316]Steps:   7%|▋         | 150/2220 [51:20<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.33] Steps:   7%|▋         | 150/2220 [51:22<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.0783]Steps:   7%|▋         | 150/2220 [51:24<12:07:52, 21.10s/it, lr=0.0001, step_loss=0.354] Steps:   7%|▋         | 151/2220 [51:26<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.354]Steps:   7%|▋         | 151/2220 [51:26<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.11] Steps:   7%|▋         | 151/2220 [51:28<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.253]Steps:   7%|▋         | 151/2220 [51:30<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.412]Steps:   7%|▋         | 151/2220 [51:32<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.234]Steps:   7%|▋         | 151/2220 [51:34<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.162]Steps:   7%|▋         | 151/2220 [51:36<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.159]Steps:   7%|▋         | 151/2220 [51:38<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.165]Steps:   7%|▋         | 151/2220 [51:40<11:10:15, 19.44s/it, lr=0.0001, step_loss=0.159]Steps:   7%|▋         | 152/2220 [51:42<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.159]Steps:   7%|▋         | 152/2220 [51:42<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.259]Steps:   7%|▋         | 152/2220 [51:44<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.381]Steps:   7%|▋         | 152/2220 [51:46<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.242]Steps:   7%|▋         | 152/2220 [51:48<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.11] Steps:   7%|▋         | 152/2220 [51:50<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.143]Steps:   7%|▋         | 152/2220 [51:52<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.0911]Steps:   7%|▋         | 152/2220 [51:53<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.179] Steps:   7%|▋         | 152/2220 [51:55<10:31:06, 18.31s/it, lr=0.0001, step_loss=0.119]Steps:   7%|▋         | 153/2220 [51:58<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.119]Steps:   7%|▋         | 153/2220 [51:58<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.107]Steps:   7%|▋         | 153/2220 [51:59<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.302]Steps:   7%|▋         | 153/2220 [52:01<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.116]Steps:   7%|▋         | 153/2220 [52:03<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.169]Steps:   7%|▋         | 153/2220 [52:05<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.0836]Steps:   7%|▋         | 153/2220 [52:07<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.119] Steps:   7%|▋         | 153/2220 [52:09<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.501]Steps:   7%|▋         | 153/2220 [52:12<10:02:09, 17.48s/it, lr=0.0001, step_loss=0.188]Steps:   7%|▋         | 154/2220 [52:14<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.188] Steps:   7%|▋         | 154/2220 [52:14<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.088]Steps:   7%|▋         | 154/2220 [52:16<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.0626]Steps:   7%|▋         | 154/2220 [52:18<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.238] Steps:   7%|▋         | 154/2220 [52:19<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.133]Steps:   7%|▋         | 154/2220 [52:21<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.114]Steps:   7%|▋         | 154/2220 [52:23<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.196]Steps:   7%|▋         | 154/2220 [52:25<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.211]Steps:   7%|▋         | 154/2220 [52:27<9:45:57, 17.02s/it, lr=0.0001, step_loss=0.109]Steps:   7%|▋         | 155/2220 [52:29<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.109]Steps:   7%|▋         | 155/2220 [52:29<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.308]Steps:   7%|▋         | 155/2220 [52:31<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.4]  Steps:   7%|▋         | 155/2220 [52:33<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.0909]Steps:   7%|▋         | 155/2220 [52:35<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.111] Steps:   7%|▋         | 155/2220 [52:37<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.262]Steps:   7%|▋         | 155/2220 [52:39<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.16] Steps:   7%|▋         | 155/2220 [52:41<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.361]Steps:   7%|▋         | 155/2220 [52:43<9:31:23, 16.60s/it, lr=0.0001, step_loss=0.0941]Steps:   7%|▋         | 156/2220 [52:45<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.0941]Steps:   7%|▋         | 156/2220 [52:45<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.642] Steps:   7%|▋         | 156/2220 [52:47<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.0793]Steps:   7%|▋         | 156/2220 [52:49<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.317] Steps:   7%|▋         | 156/2220 [52:51<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.164]Steps:   7%|▋         | 156/2220 [52:53<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.103]Steps:   7%|▋         | 156/2220 [52:55<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.111]Steps:   7%|▋         | 156/2220 [52:57<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.211]Steps:   7%|▋         | 156/2220 [52:59<9:23:17, 16.37s/it, lr=0.0001, step_loss=0.145]Steps:   7%|▋         | 157/2220 [53:01<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.145]Steps:   7%|▋         | 157/2220 [53:01<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.395]Steps:   7%|▋         | 157/2220 [53:03<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.488]Steps:   7%|▋         | 157/2220 [53:05<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.352]Steps:   7%|▋         | 157/2220 [53:07<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.0793]Steps:   7%|▋         | 157/2220 [53:08<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.0775]Steps:   7%|▋         | 157/2220 [53:10<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.22]  Steps:   7%|▋         | 157/2220 [53:12<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.0954]Steps:   7%|▋         | 157/2220 [53:14<9:17:18, 16.21s/it, lr=0.0001, step_loss=0.162] Steps:   7%|▋         | 158/2220 [53:17<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.162]Steps:   7%|▋         | 158/2220 [53:17<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.412]Steps:   7%|▋         | 158/2220 [53:18<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.0692]Steps:   7%|▋         | 158/2220 [53:20<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.182] Steps:   7%|▋         | 158/2220 [53:22<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.111]Steps:   7%|▋         | 158/2220 [53:24<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.22] Steps:   7%|▋         | 158/2220 [53:26<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.0638]Steps:   7%|▋         | 158/2220 [53:28<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.176] Steps:   7%|▋         | 158/2220 [53:30<9:11:37, 16.05s/it, lr=0.0001, step_loss=0.0622]Steps:   7%|▋         | 159/2220 [53:32<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.0622]Steps:   7%|▋         | 159/2220 [53:32<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.228] Steps:   7%|▋         | 159/2220 [53:34<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.19] Steps:   7%|▋         | 159/2220 [53:36<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.151]Steps:   7%|▋         | 159/2220 [53:38<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.156]Steps:   7%|▋         | 159/2220 [53:40<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.0926]Steps:   7%|▋         | 159/2220 [53:42<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.11]  Steps:   7%|▋         | 159/2220 [53:44<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.493]Steps:   7%|▋         | 159/2220 [53:46<9:06:34, 15.91s/it, lr=0.0001, step_loss=0.118]Steps:   7%|▋         | 160/2220 [53:48<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.118]11/29/2024 00:02:31 - INFO - __main__ - Step 160: Test Loss = 0.1746
Steps:   7%|▋         | 160/2220 [55:20<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.135]Steps:   7%|▋         | 160/2220 [55:21<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.118]Steps:   7%|▋         | 160/2220 [55:23<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.107]Steps:   7%|▋         | 160/2220 [55:25<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.115]Steps:   7%|▋         | 160/2220 [55:26<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.0891]Steps:   7%|▋         | 160/2220 [55:28<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.068] Steps:   7%|▋         | 160/2220 [55:30<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.101]Steps:   7%|▋         | 160/2220 [55:32<9:06:18, 15.91s/it, lr=0.0001, step_loss=0.0914]Steps:   7%|▋         | 161/2220 [55:34<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.0914]Steps:   7%|▋         | 161/2220 [55:35<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.313] Steps:   7%|▋         | 161/2220 [55:37<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.102]Steps:   7%|▋         | 161/2220 [55:39<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.168]Steps:   7%|▋         | 161/2220 [55:40<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.168]Steps:   7%|▋         | 161/2220 [55:42<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.101]Steps:   7%|▋         | 161/2220 [55:44<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.277]Steps:   7%|▋         | 161/2220 [55:46<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.092]Steps:   7%|▋         | 161/2220 [55:48<24:38:10, 43.07s/it, lr=0.0001, step_loss=0.067]Steps:   7%|▋         | 162/2220 [55:50<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.067]Steps:   7%|▋         | 162/2220 [55:50<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.25] Steps:   7%|▋         | 162/2220 [55:52<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.101]Steps:   7%|▋         | 162/2220 [55:54<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.0973]Steps:   7%|▋         | 162/2220 [55:56<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.0725]Steps:   7%|▋         | 162/2220 [55:58<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.149] Steps:   7%|▋         | 162/2220 [56:00<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.188]Steps:   7%|▋         | 162/2220 [56:02<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.321]Steps:   7%|▋         | 162/2220 [56:04<19:56:21, 34.88s/it, lr=0.0001, step_loss=0.214]Steps:   7%|▋         | 163/2220 [56:06<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.214]Steps:   7%|▋         | 163/2220 [56:06<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.117]Steps:   7%|▋         | 163/2220 [56:08<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.196]Steps:   7%|▋         | 163/2220 [56:10<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.194]Steps:   7%|▋         | 163/2220 [56:12<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.0755]Steps:   7%|▋         | 163/2220 [56:14<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.284] Steps:   7%|▋         | 163/2220 [56:15<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.131]Steps:   7%|▋         | 163/2220 [56:17<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.14] Steps:   7%|▋         | 163/2220 [56:19<16:39:48, 29.16s/it, lr=0.0001, step_loss=0.226]Steps:   7%|▋         | 164/2220 [56:22<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.226]Steps:   7%|▋         | 164/2220 [56:22<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.207]Steps:   7%|▋         | 164/2220 [56:23<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.155]Steps:   7%|▋         | 164/2220 [56:25<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.184]Steps:   7%|▋         | 164/2220 [56:27<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.301]Steps:   7%|▋         | 164/2220 [56:29<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.298]Steps:   7%|▋         | 164/2220 [56:31<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.229]Steps:   7%|▋         | 164/2220 [56:33<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.0906]Steps:   7%|▋         | 164/2220 [56:35<14:18:22, 25.05s/it, lr=0.0001, step_loss=0.076] Steps:   7%|▋         | 165/2220 [56:37<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.076]Steps:   7%|▋         | 165/2220 [56:37<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.17] Steps:   7%|▋         | 165/2220 [56:39<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.265]Steps:   7%|▋         | 165/2220 [56:41<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.141]Steps:   7%|▋         | 165/2220 [56:43<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.216]Steps:   7%|▋         | 165/2220 [56:45<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.104]Steps:   7%|▋         | 165/2220 [56:47<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.521]Steps:   7%|▋         | 165/2220 [56:48<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.402]Steps:   7%|▋         | 165/2220 [56:50<12:40:02, 22.19s/it, lr=0.0001, step_loss=0.0853]Steps:   7%|▋         | 166/2220 [56:53<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.0853]Steps:   7%|▋         | 166/2220 [56:53<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.459] Steps:   7%|▋         | 166/2220 [56:54<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.183]Steps:   7%|▋         | 166/2220 [56:56<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.333]Steps:   7%|▋         | 166/2220 [56:58<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.29] Steps:   7%|▋         | 166/2220 [57:01<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.224]Steps:   7%|▋         | 166/2220 [57:02<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.15] Steps:   7%|▋         | 166/2220 [57:04<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.169]Steps:   7%|▋         | 166/2220 [57:06<11:30:59, 20.18s/it, lr=0.0001, step_loss=0.178]Steps:   8%|▊         | 167/2220 [57:09<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.178]Steps:   8%|▊         | 167/2220 [57:09<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.103]Steps:   8%|▊         | 167/2220 [57:10<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.115]Steps:   8%|▊         | 167/2220 [57:12<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.527]Steps:   8%|▊         | 167/2220 [57:14<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.188]Steps:   8%|▊         | 167/2220 [57:16<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.111]Steps:   8%|▊         | 167/2220 [57:18<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.183]Steps:   8%|▊         | 167/2220 [57:20<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.0939]Steps:   8%|▊         | 167/2220 [57:22<10:47:21, 18.92s/it, lr=0.0001, step_loss=0.189] Steps:   8%|▊         | 168/2220 [57:24<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.189]Steps:   8%|▊         | 168/2220 [57:24<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.278]Steps:   8%|▊         | 168/2220 [57:26<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.262]Steps:   8%|▊         | 168/2220 [57:29<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.0947]Steps:   8%|▊         | 168/2220 [57:31<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.16]  Steps:   8%|▊         | 168/2220 [57:32<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.231]Steps:   8%|▊         | 168/2220 [57:34<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.402]Steps:   8%|▊         | 168/2220 [57:36<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.394]Steps:   8%|▊         | 168/2220 [57:38<10:13:38, 17.94s/it, lr=0.0001, step_loss=0.214]Steps:   8%|▊         | 169/2220 [57:40<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.214] Steps:   8%|▊         | 169/2220 [57:40<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.11] Steps:   8%|▊         | 169/2220 [57:42<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.137]Steps:   8%|▊         | 169/2220 [57:44<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.141]Steps:   8%|▊         | 169/2220 [57:46<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.104]Steps:   8%|▊         | 169/2220 [57:48<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.231]Steps:   8%|▊         | 169/2220 [57:50<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.254]Steps:   8%|▊         | 169/2220 [57:52<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.22] Steps:   8%|▊         | 169/2220 [57:54<9:53:43, 17.37s/it, lr=0.0001, step_loss=0.134]Steps:   8%|▊         | 170/2220 [57:56<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.134]Steps:   8%|▊         | 170/2220 [57:56<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.111]Steps:   8%|▊         | 170/2220 [57:58<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.311]Steps:   8%|▊         | 170/2220 [57:59<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.142]Steps:   8%|▊         | 170/2220 [58:01<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.184]Steps:   8%|▊         | 170/2220 [58:03<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.21] Steps:   8%|▊         | 170/2220 [58:05<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.273]Steps:   8%|▊         | 170/2220 [58:07<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.477]Steps:   8%|▊         | 170/2220 [58:09<9:34:27, 16.81s/it, lr=0.0001, step_loss=0.367]Steps:   8%|▊         | 171/2220 [58:12<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.367]Steps:   8%|▊         | 171/2220 [58:12<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.227]Steps:   8%|▊         | 171/2220 [58:13<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.32] Steps:   8%|▊         | 171/2220 [58:15<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.453]Steps:   8%|▊         | 171/2220 [58:17<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.173]Steps:   8%|▊         | 171/2220 [58:19<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.234]Steps:   8%|▊         | 171/2220 [58:21<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.0996]Steps:   8%|▊         | 171/2220 [58:23<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.146] Steps:   8%|▊         | 171/2220 [58:25<9:24:49, 16.54s/it, lr=0.0001, step_loss=0.234]Steps:   8%|▊         | 172/2220 [58:27<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.234]Steps:   8%|▊         | 172/2220 [58:27<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.269]Steps:   8%|▊         | 172/2220 [58:29<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.327]Steps:   8%|▊         | 172/2220 [58:31<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.14] Steps:   8%|▊         | 172/2220 [58:33<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.0808]Steps:   8%|▊         | 172/2220 [58:35<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.204] Steps:   8%|▊         | 172/2220 [58:37<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.122]Steps:   8%|▊         | 172/2220 [58:39<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.103]Steps:   8%|▊         | 172/2220 [58:40<9:12:47, 16.20s/it, lr=0.0001, step_loss=0.0905]Steps:   8%|▊         | 173/2220 [58:43<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.0905]Steps:   8%|▊         | 173/2220 [58:43<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.147] Steps:   8%|▊         | 173/2220 [58:45<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.164]Steps:   8%|▊         | 173/2220 [58:47<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.0931]Steps:   8%|▊         | 173/2220 [58:49<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.0739]Steps:   8%|▊         | 173/2220 [58:50<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.297] Steps:   8%|▊         | 173/2220 [58:52<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.184]Steps:   8%|▊         | 173/2220 [58:54<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.207]Steps:   8%|▊         | 173/2220 [58:56<9:09:20, 16.10s/it, lr=0.0001, step_loss=0.152]Steps:   8%|▊         | 174/2220 [58:58<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.152]Steps:   8%|▊         | 174/2220 [58:58<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.15] Steps:   8%|▊         | 174/2220 [59:00<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.155]Steps:   8%|▊         | 174/2220 [59:03<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.123]Steps:   8%|▊         | 174/2220 [59:04<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.282]Steps:   8%|▊         | 174/2220 [59:06<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.128]Steps:   8%|▊         | 174/2220 [59:08<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.113]Steps:   8%|▊         | 174/2220 [59:10<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.336]Steps:   8%|▊         | 174/2220 [59:12<9:01:43, 15.89s/it, lr=0.0001, step_loss=0.381]Steps:   8%|▊         | 175/2220 [59:14<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.381]Steps:   8%|▊         | 175/2220 [59:14<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.159]Steps:   8%|▊         | 175/2220 [59:16<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.477]Steps:   8%|▊         | 175/2220 [59:18<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.14] Steps:   8%|▊         | 175/2220 [59:20<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.0764]Steps:   8%|▊         | 175/2220 [59:22<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.333] Steps:   8%|▊         | 175/2220 [59:24<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.214]Steps:   8%|▊         | 175/2220 [59:26<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.111]Steps:   8%|▊         | 175/2220 [59:28<9:03:52, 15.96s/it, lr=0.0001, step_loss=0.214]Steps:   8%|▊         | 176/2220 [59:30<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.214]Steps:   8%|▊         | 176/2220 [59:30<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.223]Steps:   8%|▊         | 176/2220 [59:32<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.109]Steps:   8%|▊         | 176/2220 [59:34<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.171]Steps:   8%|▊         | 176/2220 [59:35<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.373]Steps:   8%|▊         | 176/2220 [59:37<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.122]Steps:   8%|▊         | 176/2220 [59:39<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.153]Steps:   8%|▊         | 176/2220 [59:41<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.154]Steps:   8%|▊         | 176/2220 [59:43<8:58:55, 15.82s/it, lr=0.0001, step_loss=0.0982]Steps:   8%|▊         | 177/2220 [59:45<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.0982]Steps:   8%|▊         | 177/2220 [59:45<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.183] Steps:   8%|▊         | 177/2220 [59:47<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.285]Steps:   8%|▊         | 177/2220 [59:49<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.0996]Steps:   8%|▊         | 177/2220 [59:51<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.159] Steps:   8%|▊         | 177/2220 [59:53<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.525]Steps:   8%|▊         | 177/2220 [59:55<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.228]Steps:   8%|▊         | 177/2220 [59:57<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.0686]Steps:   8%|▊         | 177/2220 [59:59<8:55:21, 15.72s/it, lr=0.0001, step_loss=0.178] Steps:   8%|▊         | 178/2220 [1:00:01<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.178]Steps:   8%|▊         | 178/2220 [1:00:01<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.175]Steps:   8%|▊         | 178/2220 [1:00:03<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.418]Steps:   8%|▊         | 178/2220 [1:00:05<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.23] Steps:   8%|▊         | 178/2220 [1:00:06<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.228]Steps:   8%|▊         | 178/2220 [1:00:08<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.0854]Steps:   8%|▊         | 178/2220 [1:00:11<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.116] Steps:   8%|▊         | 178/2220 [1:00:13<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.152]Steps:   8%|▊         | 178/2220 [1:00:15<8:52:56, 15.66s/it, lr=0.0001, step_loss=0.311]Steps:   8%|▊         | 179/2220 [1:00:17<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.311]Steps:   8%|▊         | 179/2220 [1:00:17<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.0954]Steps:   8%|▊         | 179/2220 [1:00:19<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.154] Steps:   8%|▊         | 179/2220 [1:00:20<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.109]Steps:   8%|▊         | 179/2220 [1:00:22<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.1]  Steps:   8%|▊         | 179/2220 [1:00:24<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.47]Steps:   8%|▊         | 179/2220 [1:00:26<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.0727]Steps:   8%|▊         | 179/2220 [1:00:28<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.348] Steps:   8%|▊         | 179/2220 [1:00:30<8:52:59, 15.67s/it, lr=0.0001, step_loss=0.135]Steps:   8%|▊         | 180/2220 [1:00:32<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.135]11/29/2024 00:09:13 - INFO - __main__ - Step 180: Test Loss = 0.1743
Steps:   8%|▊         | 180/2220 [1:02:02<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.535]Steps:   8%|▊         | 180/2220 [1:02:05<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.139]Steps:   8%|▊         | 180/2220 [1:02:06<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.0771]Steps:   8%|▊         | 180/2220 [1:02:09<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.0953]Steps:   8%|▊         | 180/2220 [1:02:11<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.143] Steps:   8%|▊         | 180/2220 [1:02:12<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.103]Steps:   8%|▊         | 180/2220 [1:02:14<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.198]Steps:   8%|▊         | 180/2220 [1:02:16<8:52:40, 15.67s/it, lr=0.0001, step_loss=0.102]Steps:   8%|▊         | 181/2220 [1:02:18<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.102]Steps:   8%|▊         | 181/2220 [1:02:18<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.149]Steps:   8%|▊         | 181/2220 [1:02:20<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.534]Steps:   8%|▊         | 181/2220 [1:02:22<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.129]Steps:   8%|▊         | 181/2220 [1:02:24<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.142]Steps:   8%|▊         | 181/2220 [1:02:26<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.116]Steps:   8%|▊         | 181/2220 [1:02:28<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.173]Steps:   8%|▊         | 181/2220 [1:02:30<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.489]Steps:   8%|▊         | 181/2220 [1:02:32<24:12:24, 42.74s/it, lr=0.0001, step_loss=0.115]Steps:   8%|▊         | 182/2220 [1:02:34<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.115]Steps:   8%|▊         | 182/2220 [1:02:34<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.391]Steps:   8%|▊         | 182/2220 [1:02:36<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.237]Steps:   8%|▊         | 182/2220 [1:02:38<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.448]Steps:   8%|▊         | 182/2220 [1:02:40<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.243]Steps:   8%|▊         | 182/2220 [1:02:41<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.111]Steps:   8%|▊         | 182/2220 [1:02:43<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.104]Steps:   8%|▊         | 182/2220 [1:02:45<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.301]Steps:   8%|▊         | 182/2220 [1:02:47<19:37:47, 34.67s/it, lr=0.0001, step_loss=0.137]Steps:   8%|▊         | 183/2220 [1:02:49<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.137]Steps:   8%|▊         | 183/2220 [1:02:49<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.17] Steps:   8%|▊         | 183/2220 [1:02:51<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.278]Steps:   8%|▊         | 183/2220 [1:02:53<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.355]Steps:   8%|▊         | 183/2220 [1:02:55<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.19] Steps:   8%|▊         | 183/2220 [1:02:57<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.216]Steps:   8%|▊         | 183/2220 [1:02:59<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.357]Steps:   8%|▊         | 183/2220 [1:03:01<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.167]Steps:   8%|▊         | 183/2220 [1:03:03<16:20:34, 28.88s/it, lr=0.0001, step_loss=0.393]Steps:   8%|▊         | 184/2220 [1:03:05<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.393]Steps:   8%|▊         | 184/2220 [1:03:05<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.0922]Steps:   8%|▊         | 184/2220 [1:03:07<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.146] Steps:   8%|▊         | 184/2220 [1:03:09<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.418]Steps:   8%|▊         | 184/2220 [1:03:11<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.289]Steps:   8%|▊         | 184/2220 [1:03:13<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.211]Steps:   8%|▊         | 184/2220 [1:03:14<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.169]Steps:   8%|▊         | 184/2220 [1:03:17<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.378]Steps:   8%|▊         | 184/2220 [1:03:19<14:06:05, 24.93s/it, lr=0.0001, step_loss=0.404]Steps:   8%|▊         | 185/2220 [1:03:21<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.404]Steps:   8%|▊         | 185/2220 [1:03:21<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.0671]Steps:   8%|▊         | 185/2220 [1:03:23<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.26]  Steps:   8%|▊         | 185/2220 [1:03:24<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.312]Steps:   8%|▊         | 185/2220 [1:03:26<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.19] Steps:   8%|▊         | 185/2220 [1:03:28<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.19]Steps:   8%|▊         | 185/2220 [1:03:30<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.142]Steps:   8%|▊         | 185/2220 [1:03:32<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.33] Steps:   8%|▊         | 185/2220 [1:03:34<12:31:17, 22.15s/it, lr=0.0001, step_loss=0.2] Steps:   8%|▊         | 186/2220 [1:03:36<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.2]Steps:   8%|▊         | 186/2220 [1:03:36<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.0958]Steps:   8%|▊         | 186/2220 [1:03:38<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.105] Steps:   8%|▊         | 186/2220 [1:03:40<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.0854]Steps:   8%|▊         | 186/2220 [1:03:42<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.151] Steps:   8%|▊         | 186/2220 [1:03:44<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.206]Steps:   8%|▊         | 186/2220 [1:03:46<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.137]Steps:   8%|▊         | 186/2220 [1:03:48<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.082]Steps:   8%|▊         | 186/2220 [1:03:50<11:25:14, 20.21s/it, lr=0.0001, step_loss=0.0832]Steps:   8%|▊         | 187/2220 [1:03:52<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.0832]Steps:   8%|▊         | 187/2220 [1:03:52<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.385] Steps:   8%|▊         | 187/2220 [1:03:54<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.0747]Steps:   8%|▊         | 187/2220 [1:03:56<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.0984]Steps:   8%|▊         | 187/2220 [1:03:58<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.317] Steps:   8%|▊         | 187/2220 [1:03:59<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.0982]Steps:   8%|▊         | 187/2220 [1:04:01<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.264] Steps:   8%|▊         | 187/2220 [1:04:03<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.117]Steps:   8%|▊         | 187/2220 [1:04:05<10:36:53, 18.80s/it, lr=0.0001, step_loss=0.315]Steps:   8%|▊         | 188/2220 [1:04:07<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.315]Steps:   8%|▊         | 188/2220 [1:04:08<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.499]Steps:   8%|▊         | 188/2220 [1:04:09<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.201]Steps:   8%|▊         | 188/2220 [1:04:11<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.327]Steps:   8%|▊         | 188/2220 [1:04:13<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.288]Steps:   8%|▊         | 188/2220 [1:04:16<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.106]Steps:   8%|▊         | 188/2220 [1:04:17<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.106]Steps:   8%|▊         | 188/2220 [1:04:19<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.0815]Steps:   8%|▊         | 188/2220 [1:04:21<10:03:33, 17.82s/it, lr=0.0001, step_loss=0.155] Steps:   9%|▊         | 189/2220 [1:04:23<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.155] Steps:   9%|▊         | 189/2220 [1:04:23<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.525]Steps:   9%|▊         | 189/2220 [1:04:25<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.326]Steps:   9%|▊         | 189/2220 [1:04:27<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.186]Steps:   9%|▊         | 189/2220 [1:04:29<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.458]Steps:   9%|▊         | 189/2220 [1:04:31<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.205]Steps:   9%|▊         | 189/2220 [1:04:33<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.0966]Steps:   9%|▊         | 189/2220 [1:04:35<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.117] Steps:   9%|▊         | 189/2220 [1:04:36<9:42:04, 17.20s/it, lr=0.0001, step_loss=0.123]Steps:   9%|▊         | 190/2220 [1:04:39<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.123]Steps:   9%|▊         | 190/2220 [1:04:39<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.157]Steps:   9%|▊         | 190/2220 [1:04:41<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.259]Steps:   9%|▊         | 190/2220 [1:04:42<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.154]Steps:   9%|▊         | 190/2220 [1:04:44<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.239]Steps:   9%|▊         | 190/2220 [1:04:46<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.275]Steps:   9%|▊         | 190/2220 [1:04:49<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.347]Steps:   9%|▊         | 190/2220 [1:04:50<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.127]Steps:   9%|▊         | 190/2220 [1:04:52<9:25:16, 16.71s/it, lr=0.0001, step_loss=0.104]Steps:   9%|▊         | 191/2220 [1:04:54<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.104]Steps:   9%|▊         | 191/2220 [1:04:54<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.449]Steps:   9%|▊         | 191/2220 [1:04:56<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.13] Steps:   9%|▊         | 191/2220 [1:04:58<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.138]Steps:   9%|▊         | 191/2220 [1:05:00<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.223]Steps:   9%|▊         | 191/2220 [1:05:02<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.119]Steps:   9%|▊         | 191/2220 [1:05:04<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.311]Steps:   9%|▊         | 191/2220 [1:05:06<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.559]Steps:   9%|▊         | 191/2220 [1:05:08<9:12:47, 16.35s/it, lr=0.0001, step_loss=0.133]Steps:   9%|▊         | 192/2220 [1:05:10<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.133]Steps:   9%|▊         | 192/2220 [1:05:10<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.203]Steps:   9%|▊         | 192/2220 [1:05:12<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.205]Steps:   9%|▊         | 192/2220 [1:05:14<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.119]Steps:   9%|▊         | 192/2220 [1:05:16<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.338]Steps:   9%|▊         | 192/2220 [1:05:18<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.101]Steps:   9%|▊         | 192/2220 [1:05:20<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.212]Steps:   9%|▊         | 192/2220 [1:05:22<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.142]Steps:   9%|▊         | 192/2220 [1:05:23<9:05:14, 16.13s/it, lr=0.0001, step_loss=0.102]Steps:   9%|▊         | 193/2220 [1:05:26<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.102]Steps:   9%|▊         | 193/2220 [1:05:26<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.201]Steps:   9%|▊         | 193/2220 [1:05:27<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.114]Steps:   9%|▊         | 193/2220 [1:05:29<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.362]Steps:   9%|▊         | 193/2220 [1:05:31<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.105]Steps:   9%|▊         | 193/2220 [1:05:33<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.183]Steps:   9%|▊         | 193/2220 [1:05:35<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.114]Steps:   9%|▊         | 193/2220 [1:05:37<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.0902]Steps:   9%|▊         | 193/2220 [1:05:39<8:59:32, 15.97s/it, lr=0.0001, step_loss=0.104] Steps:   9%|▊         | 194/2220 [1:05:41<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.104]Steps:   9%|▊         | 194/2220 [1:05:41<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.277]Steps:   9%|▊         | 194/2220 [1:05:43<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.104]Steps:   9%|▊         | 194/2220 [1:05:45<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.197]Steps:   9%|▊         | 194/2220 [1:05:47<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.0675]Steps:   9%|▊         | 194/2220 [1:05:49<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.397] Steps:   9%|▊         | 194/2220 [1:05:51<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.13] Steps:   9%|▊         | 194/2220 [1:05:53<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.201]Steps:   9%|▊         | 194/2220 [1:05:55<8:56:18, 15.88s/it, lr=0.0001, step_loss=0.109]Steps:   9%|▉         | 195/2220 [1:05:57<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.109]Steps:   9%|▉         | 195/2220 [1:05:57<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.199]Steps:   9%|▉         | 195/2220 [1:05:59<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.16] Steps:   9%|▉         | 195/2220 [1:06:01<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.0644]Steps:   9%|▉         | 195/2220 [1:06:02<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.123] Steps:   9%|▉         | 195/2220 [1:06:05<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.119]Steps:   9%|▉         | 195/2220 [1:06:07<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.405]Steps:   9%|▉         | 195/2220 [1:06:08<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.184]Steps:   9%|▉         | 195/2220 [1:06:10<8:53:36, 15.81s/it, lr=0.0001, step_loss=0.203]Steps:   9%|▉         | 196/2220 [1:06:13<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.203]Steps:   9%|▉         | 196/2220 [1:06:13<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.202]Steps:   9%|▉         | 196/2220 [1:06:14<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.0848]Steps:   9%|▉         | 196/2220 [1:06:16<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.251] Steps:   9%|▉         | 196/2220 [1:06:18<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.302]Steps:   9%|▉         | 196/2220 [1:06:20<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.0682]Steps:   9%|▉         | 196/2220 [1:06:22<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.116] Steps:   9%|▉         | 196/2220 [1:06:25<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.12] Steps:   9%|▉         | 196/2220 [1:06:26<8:52:35, 15.79s/it, lr=0.0001, step_loss=0.152]Steps:   9%|▉         | 197/2220 [1:06:29<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.152]Steps:   9%|▉         | 197/2220 [1:06:29<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.203]Steps:   9%|▉         | 197/2220 [1:06:30<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.163]Steps:   9%|▉         | 197/2220 [1:06:32<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.0933]Steps:   9%|▉         | 197/2220 [1:06:34<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.219] Steps:   9%|▉         | 197/2220 [1:06:36<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.208]Steps:   9%|▉         | 197/2220 [1:06:38<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.195]Steps:   9%|▉         | 197/2220 [1:06:40<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.216]Steps:   9%|▉         | 197/2220 [1:06:42<8:53:45, 15.83s/it, lr=0.0001, step_loss=0.114]Steps:   9%|▉         | 198/2220 [1:06:44<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.114]Steps:   9%|▉         | 198/2220 [1:06:44<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.185]Steps:   9%|▉         | 198/2220 [1:06:46<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.125]Steps:   9%|▉         | 198/2220 [1:06:48<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.274]Steps:   9%|▉         | 198/2220 [1:06:50<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.134]Steps:   9%|▉         | 198/2220 [1:06:51<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.52] Steps:   9%|▉         | 198/2220 [1:06:53<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.255]Steps:   9%|▉         | 198/2220 [1:06:55<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.132]Steps:   9%|▉         | 198/2220 [1:06:57<8:49:26, 15.71s/it, lr=0.0001, step_loss=0.199]Steps:   9%|▉         | 199/2220 [1:07:00<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.199]Steps:   9%|▉         | 199/2220 [1:07:00<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.355]Steps:   9%|▉         | 199/2220 [1:07:02<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.211]Steps:   9%|▉         | 199/2220 [1:07:04<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.175]Steps:   9%|▉         | 199/2220 [1:07:05<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.13] Steps:   9%|▉         | 199/2220 [1:07:07<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.219]Steps:   9%|▉         | 199/2220 [1:07:09<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.477]Steps:   9%|▉         | 199/2220 [1:07:11<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.113]Steps:   9%|▉         | 199/2220 [1:07:13<8:47:53, 15.67s/it, lr=0.0001, step_loss=0.114]Steps:   9%|▉         | 200/2220 [1:07:15<8:48:14, 15.69s/it, lr=0.0001, step_loss=0.114]11/29/2024 00:15:57 - INFO - __main__ - Step 200: Test Loss = 0.1640
11/29/2024 00:15:57 - INFO - __main__ - Running validation... 
 Generating 1 videos.
[2024-11-29 00:15:58,435] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)
Warning: The cache directory for DeepSpeed Triton autotune, /fs/nexus-scratch/sjxu/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_con.py", line 1883, in <module>
    vae=accelerator.unwrap_model(vae),
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_con.py", line 1723, in main
    (global_step % args.validation_steps == 0)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py", line 2540, in unwrap_model
    return extract_model_from_parallel(model, keep_fp32_wrapper)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/utils/other.py", line 80, in extract_model_from_parallel
    from deepspeed import DeepSpeedEngine
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/__init__.py", line 25, in <module>
    from . import ops
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
    from ..git_version_info import compatible_ops as __compatible_ops__
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/git_version_info.py", line 29, in <module>
    op_compatible = builder.is_compatible()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
    sys_cuda_major, _ = installed_cuda_version()
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 51, in installed_cuda_version
    raise MissingCUDAException("CUDA_HOME does not exist, unable to compile CUDA op(s)")
deepspeed.ops.op_builder.builder.MissingCUDAException: CUDA_HOME does not exist, unable to compile CUDA op(s)
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_con.py", line 1883, in <module>
[rank0]:     vae=accelerator.unwrap_model(vae),
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_con.py", line 1723, in main
[rank0]:     (global_step % args.validation_steps == 0)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/accelerator.py", line 2540, in unwrap_model
[rank0]:     return extract_model_from_parallel(model, keep_fp32_wrapper)
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/utils/other.py", line 80, in extract_model_from_parallel
[rank0]:     from deepspeed import DeepSpeedEngine
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/__init__.py", line 25, in <module>
[rank0]:     from . import ops
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/__init__.py", line 15, in <module>
[rank0]:     from ..git_version_info import compatible_ops as __compatible_ops__
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/git_version_info.py", line 29, in <module>
[rank0]:     op_compatible = builder.is_compatible()
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/op_builder/fp_quantizer.py", line 35, in is_compatible
[rank0]:     sys_cuda_major, _ = installed_cuda_version()
[rank0]:   File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/deepspeed/ops/op_builder/builder.py", line 51, in installed_cuda_version
[rank0]:     raise MissingCUDAException("CUDA_HOME does not exist, unable to compile CUDA op(s)")
[rank0]: deepspeed.ops.op_builder.builder.MissingCUDAException: CUDA_HOME does not exist, unable to compile CUDA op(s)
wandb: - 0.779 MB of 0.779 MB uploadedwandb: \ 0.779 MB of 0.779 MB uploadedwandb: | 0.794 MB of 0.817 MB uploadedwandb: / 0.817 MB of 0.817 MB uploadedwandb: 
wandb: Run history:
wandb:  test_loss ▁▁▁▁███████████▁████▇▇▇▇▇▇▇▇▇▇▁▁▇▇▇▇▇▇▇▇
wandb: train_loss ▅▇▅▆▇▅▅▅▆▅█▅▆▅▅▆▅▅▆▅█▆▄▃▆▅▅▅▅▁▄▅▅▅▅▅▆▄█▅
wandb: 
wandb: Run summary:
wandb:  test_loss 0.16405
wandb: train_loss 0.19624
wandb: 
wandb: 🚀 View run solar-monkey-74 at: https://wandb.ai/sjxu_gamma/SVD_Con_Mul/runs/ztiv9q6l
wandb: ⭐️ View project at: https://wandb.ai/sjxu_gamma/SVD_Con_Mul
wandb: Synced 6 W&B file(s), 4 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_230708-ztiv9q6l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
W1129 00:16:08.302932 140687853871872 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 662668 closing signal SIGTERM
W1129 00:16:08.303270 140687853871872 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 662669 closing signal SIGTERM
W1129 00:16:08.303383 140687853871872 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 662670 closing signal SIGTERM
E1129 00:16:09.576609 140687853871872 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 662667) of binary: /fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/python
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/bin/accelerate", line 8, in <module>
    sys.exit(main())
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 1097, in launch_command
    multi_gpu_launcher(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/accelerate/commands/launch.py", line 734, in multi_gpu_launcher
    distrib_run.run(args)
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/fs/nexus-scratch/sjxu/miniconda3/envs/svd_control/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train_svd_con.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-29_00:16:08
  host      : gammagpu12.umiacs.umd.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 662667)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
srun: error: gammagpu12: task 2: Exited with exit code 1
