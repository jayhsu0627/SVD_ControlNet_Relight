INFO:__main__:***** Running training *****
INFO:__main__:  Num examples = 4728
INFO:__main__:  Num Epochs = 120
INFO:__main__:  Instantaneous batch size per device = 1
INFO:__main__:  Total train batch size (w. parallel, distributed & accumulation) = 64
INFO:__main__:  Gradient Accumulation steps = 16
INFO:__main__:  Total optimization steps = 8880
Steps:   0%|          | 0/8880 [00:00<?, ?it/s]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.1897], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:11<?, ?it/s, lr=0.0001, step_loss=0.133]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.2058], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:13<?, ?it/s, lr=0.0001, step_loss=0.0828]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.0506], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
before downsample: torch.Size([6, 320, 64, 64]) torch.Size([6, 1280]) torch.Size([6, 77, 1024])
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.0441], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:15<?, ?it/s, lr=0.0001, step_loss=0.151]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.5411], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:18<?, ?it/s, lr=0.0001, step_loss=0.105]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.2376], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
before downsample: torch.Size([6, 320, 64, 64]) torch.Size([6, 1280]) torch.Size([6, 77, 1024])
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.5473], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:19<?, ?it/s, lr=0.0001, step_loss=0.403]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.2757], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:22<?, ?it/s, lr=0.0001, step_loss=0.158]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.2776], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:23<?, ?it/s, lr=0.0001, step_loss=0.256]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.4817], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
before downsample: torch.Size([6, 320, 64, 64]) torch.Size([6, 1280]) torch.Size([6, 77, 1024])
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.4950], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:25<?, ?it/s, lr=0.0001, step_loss=0.406]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.1763], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:27<?, ?it/s, lr=0.0001, step_loss=0.168]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([-0.1857], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
before downsample: torch.Size([6, 320, 64, 64]) torch.Size([6, 1280]) torch.Size([6, 77, 1024])
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.0173], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])

Steps:   0%|          | 0/8880 [00:29<?, ?it/s, lr=0.0001, step_loss=0.157]
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.7144], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
Steps:   0%|          | 1/8880 [00:32<79:29:09, 32.23s/it, lr=0.0001, step_loss=0.309]INFO:__main__:Running validation...
 Generating 1 videos.
encoder_hidden_states_t shape torch.Size([1, 77, 1024])
time steps: tensor([0.4951], device='cuda:0')
before controlnet: torch.Size([1, 6, 8, 64, 64]) torch.Size([1]) torch.Size([1, 77, 1024]) torch.Size([1, 3]) torch.Size([1, 6, 4, 512, 512]) torch.Size([1, 6, 1, 16])
before downsample: torch.Size([6, 320, 64, 64]) torch.Size([6, 1280]) torch.Size([6, 77, 1024])
{'controlnet'} was not found in config. Values will be initialized to default values.
                                                                     Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of stabilityai/stable-video-diffusion-img2vid.
{'final_sigmas_type', 'rescale_betas_zero_snr'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-video-diffusion-img2vid.
Loading pipeline components...: 100%|██████████| 5/5 [00:00<00:00, 274.37it/s]
Traceback (most recent call last):
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1944, in <module>
    main()
  File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1842, in main
    fps= fps,
NameError: name 'fps' is not defined
[rank0]: Traceback (most recent call last):
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1944, in <module>
[rank0]:     main()
[rank0]:   File "/fs/nexus-scratch/sjxu/svd-temporal-controlnet/train_svd_controlnet.py", line 1842, in main
[rank0]:     fps= fps,
[rank0]: NameError: name 'fps' is not defined
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
(512, 512, 3) (512, 512, 1)
here